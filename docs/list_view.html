<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
  <title>Aphasia Tech Map: Aphasia research studies</title>
  
  
  
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Aphasia Tech Map: Aphasia research studies"/>
  <meta property="og:type" content="article"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:site_name" content="Aphasia Tech Map"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Aphasia Tech Map: Aphasia research studies"/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title"]}},"value":[{"type":"character","attributes":{},"value":["Aphasia research studies"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  <!--radix_placeholder_navigation_in_header-->
  <meta name="distill:offset" content=""/>
  
  <script type="application/javascript">
  
    window.headroom_prevent_pin = false;
  
    window.document.addEventListener("DOMContentLoaded", function (event) {
  
      // initialize headroom for banner
      var header = $('header').get(0);
      var headerHeight = header.offsetHeight;
      var headroom = new Headroom(header, {
        tolerance: 5,
        onPin : function() {
          if (window.headroom_prevent_pin) {
            window.headroom_prevent_pin = false;
            headroom.unpin();
          }
        }
      });
      headroom.init();
      if(window.location.hash)
        headroom.unpin();
      $(header).addClass('headroom--transition');
  
      // offset scroll location for banner on hash change
      // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
      window.addEventListener("hashchange", function(event) {
        window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
      });
  
      // responsive menu
      $('.distill-site-header').each(function(i, val) {
        var topnav = $(this);
        var toggle = topnav.find('.nav-toggle');
        toggle.on('click', function() {
          topnav.toggleClass('responsive');
        });
      });
  
      // nav dropdowns
      $('.nav-dropbtn').click(function(e) {
        $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
        $(this).parent().siblings('.nav-dropdown')
           .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $("body").click(function(e){
        $('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $(".nav-dropdown").click(function(e){
        e.stopPropagation();
      });
    });
  </script>
  
  <style type="text/css">
  
  /* Theme (user-documented overrideables for nav appearance) */
  
  .distill-site-nav {
    color: rgba(255, 255, 255, 0.8);
    background-color: #0F2E3D;
    font-size: 15px;
    font-weight: 300;
  }
  
  .distill-site-nav a {
    color: inherit;
    text-decoration: none;
  }
  
  .distill-site-nav a:hover {
    color: white;
  }
  
  @media print {
    .distill-site-nav {
      display: none;
    }
  }
  
  .distill-site-header {
  
  }
  
  .distill-site-footer {
  
  }
  
  
  /* Site Header */
  
  .distill-site-header {
    width: 100%;
    box-sizing: border-box;
    z-index: 3;
  }
  
  .distill-site-header .nav-left {
    display: inline-block;
    margin-left: 8px;
  }
  
  @media screen and (max-width: 768px) {
    .distill-site-header .nav-left {
      margin-left: 0;
    }
  }
  
  
  .distill-site-header .nav-right {
    float: right;
    margin-right: 8px;
  }
  
  .distill-site-header a,
  .distill-site-header .title {
    display: inline-block;
    text-align: center;
    padding: 14px 10px 14px 10px;
  }
  
  .distill-site-header .title {
    font-size: 18px;
    min-width: 150px;
  }
  
  .distill-site-header .logo {
    padding: 0;
  }
  
  .distill-site-header .logo img {
    display: none;
    max-height: 20px;
    width: auto;
    margin-bottom: -4px;
  }
  
  .distill-site-header .nav-image img {
    max-height: 18px;
    width: auto;
    display: inline-block;
    margin-bottom: -3px;
  }
  
  
  
  @media screen and (min-width: 1000px) {
    .distill-site-header .logo img {
      display: inline-block;
    }
    .distill-site-header .nav-left {
      margin-left: 20px;
    }
    .distill-site-header .nav-right {
      margin-right: 20px;
    }
    .distill-site-header .title {
      padding-left: 12px;
    }
  }
  
  
  .distill-site-header .nav-toggle {
    display: none;
  }
  
  .nav-dropdown {
    display: inline-block;
    position: relative;
  }
  
  .nav-dropdown .nav-dropbtn {
    border: none;
    outline: none;
    color: rgba(255, 255, 255, 0.8);
    padding: 16px 10px;
    background-color: transparent;
    font-family: inherit;
    font-size: inherit;
    font-weight: inherit;
    margin: 0;
    margin-top: 1px;
    z-index: 2;
  }
  
  .nav-dropdown-content {
    display: none;
    position: absolute;
    background-color: white;
    min-width: 200px;
    border: 1px solid rgba(0,0,0,0.15);
    border-radius: 4px;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
    z-index: 1;
    margin-top: 2px;
    white-space: nowrap;
    padding-top: 4px;
    padding-bottom: 4px;
  }
  
  .nav-dropdown-content hr {
    margin-top: 4px;
    margin-bottom: 4px;
    border: none;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .nav-dropdown-active {
    display: block;
  }
  
  .nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
    color: black;
    padding: 6px 24px;
    text-decoration: none;
    display: block;
    text-align: left;
  }
  
  .nav-dropdown-content .nav-dropdown-header {
    display: block;
    padding: 5px 24px;
    padding-bottom: 0;
    text-transform: uppercase;
    font-size: 14px;
    color: #999999;
    white-space: nowrap;
  }
  
  .nav-dropdown:hover .nav-dropbtn {
    color: white;
  }
  
  .nav-dropdown-content a:hover {
    background-color: #ddd;
    color: black;
  }
  
  .nav-right .nav-dropdown-content {
    margin-left: -45%;
    right: 0;
  }
  
  @media screen and (max-width: 768px) {
    .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
    .distill-site-header a.nav-toggle {
      float: right;
      display: block;
    }
    .distill-site-header .title {
      margin-left: 0;
    }
    .distill-site-header .nav-right {
      margin-right: 0;
    }
    .distill-site-header {
      overflow: hidden;
    }
    .nav-right .nav-dropdown-content {
      margin-left: 0;
    }
  }
  
  
  @media screen and (max-width: 768px) {
    .distill-site-header.responsive {position: relative; min-height: 500px; }
    .distill-site-header.responsive a.nav-toggle {
      position: absolute;
      right: 0;
      top: 0;
    }
    .distill-site-header.responsive a,
    .distill-site-header.responsive .nav-dropdown {
      display: block;
      text-align: left;
    }
    .distill-site-header.responsive .nav-left,
    .distill-site-header.responsive .nav-right {
      width: 100%;
    }
    .distill-site-header.responsive .nav-dropdown {float: none;}
    .distill-site-header.responsive .nav-dropdown-content {position: relative;}
    .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
      display: block;
      width: 100%;
      text-align: left;
    }
  }
  
  /* Site Footer */
  
  .distill-site-footer {
    width: 100%;
    overflow: hidden;
    box-sizing: border-box;
    z-index: 3;
    margin-top: 30px;
    padding-top: 30px;
    padding-bottom: 30px;
    text-align: center;
  }
  
  /* Headroom */
  
  d-title {
    padding-top: 6rem;
  }
  
  @media print {
    d-title {
      padding-top: 4rem;
    }
  }
  
  .headroom {
    z-index: 1000;
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
  }
  
  .headroom--transition {
    transition: all .4s ease-in-out;
  }
  
  .headroom--unpinned {
    top: -100px;
  }
  
  .headroom--pinned {
    top: 0;
  }
  
  /* adjust viewport for navbar height */
  /* helps vertically center bootstrap (non-distill) content */
  .min-vh-100 {
    min-height: calc(100vh - 100px) !important;
  }
  
  </style>
  
  <script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"/>
  <link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"/>
  <script src="site_libs/headroom-0.9.4/headroom.min.js"></script>
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }
  
  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }
  
  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }
  
  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }
  
  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }
  
  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }
  
  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  hr.section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    margin: 0px;
  }
  
  
  d-byline {
    border-top: none;
  }
  
  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
    border-top: none;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }
  
  d-article h3 {
    margin-top: 1.5rem;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  /* Tweak code blocks */
  
  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }
  
  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }
  
  d-article div.sourceCode {
    background-color: white;
  }
  
  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  d-article pre a {
    border-bottom: none;
  }
  
  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }
  
  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }
  
  @media(min-width: 768px) {
  
  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }
  
  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }
  
  /* tweak for Pandoc numbered line within distill */
  d-article pre.numberSource code > span {
      left: -2em;
  }
  
  d-article pre {
    font-size: 14px;
  }
  
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for d-contents */
  
  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }
  
  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }
  
  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }
  
  .d-contents li {
    list-style-type: none
  }
  
  .d-contents nav > ul {
    padding-left: 0;
  }
  
  .d-contents ul {
    padding-left: 1em
  }
  
  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }
  
  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }
  
  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }
  
  .d-contents nav > ul > li > a {
    font-weight: 600;
  }
  
  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }
  
  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }
  
  
  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }
  
  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }
  
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  /* Citations */
  
  d-article .citation {
    color: inherit;
    cursor: inherit;
  }
  
  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }
  
  /* Citation hover box */
  
  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }
  
  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  /* Include appendix styles here so they can be overridden */
  
  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }
  
  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }
  
  d-appendix h3 + * {
    margin-top: 1em;
  }
  
  d-appendix ol {
    padding: 0 0 0 15px;
  }
  
  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }
  
  d-appendix li {
    margin-bottom: 1em;
  }
  
  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  d-appendix > * {
    grid-column: text;
  }
  
  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }
  
  /* Include footnote styles here so they can be overridden */
  
  d-footnote-list {
    contain: layout style;
  }
  
  d-footnote-list > * {
    grid-column: text;
  }
  
  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }
  
  
  
  /* Anchor.js */
  
  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .custom p {
    margin-bottom: 0.5em;
  }
  
  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }
  
  /* Styles for posts lists (not auto-injected) */
  
  
  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }
  
  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }
  
  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }
  
  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }
  
  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }
  
  .post-preview-last {
    border-bottom: none !important;
  }
  
  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }
  
  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }
  
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }
  
  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }
  
  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }
  
  .posts-list .metadata > * {
    display: inline-block;
  }
  
  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }
  
  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }
  
  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }
  
  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }
  
  .posts-list img {
    opacity: 1;
  }
  
  .posts-list img[data-src] {
    opacity: 0;
  }
  
  .posts-more {
    clear: both;
  }
  
  
  .posts-sidebar {
    font-size: 16px;
  }
  
  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }
  
  .sidebar-section {
    margin-bottom: 30px;
  }
  
  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
  
  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }
  
  .categories li>a {
    border-bottom: none;
  }
  
  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }
  
  .categories .active {
    font-weight: 600;
  }
  
  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }
  
  
  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  .downlevel .posts-list .post-preview {
    color: inherit;
  }
  
  
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }
  
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // separator
    var separator = '<hr class="section-separator" style="clear: both"/>';
    // prepend separator above appendix
    $('.d-byline').before(separator);
    $('.d-article').before(separator);
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();
  
    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme, except when numbering line
    // in code chunk
    $('pre:not(.numberLines) code.sourceCode a:empty').remove();
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        var author_name = front_matter.authors[i].author
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true
  
        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });
  
      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }
  
              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-contents').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <style type="text/css">
  /* base variables */
  
  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */
  
  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */
  
  
  
  html {
    /*-- Main font sizes --*/
    --title-size:      50px;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #000000;
    --header-color:    rgba(0, 0, 0, 0.8);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    sans-serif;
    --mono-font:       monospace;
    --body-font:       sans-serif;
    --navbar-font:     sans-serif;  /* websites + blogs only */
  }
  
  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }
  
  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }
  
  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.5);
  }
  
  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */
  
  .distill-site-header {
    --title-size:       18px;
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }
  
  .distill-site-footer {
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }
  
  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */
  </style>
  <style type="text/css">
  /* base variables */
  
  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */
  
  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */
  
  
  
  html {
    /*-- Main font sizes --*/
    --title-size:      24px;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #000000;
    --header-color:    rgba(0, 0, 0, 0.8);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    sans-serif;
    --mono-font:       monospace;
    --body-font:       sans-serif;
    --navbar-font:     sans-serif;  /* websites + blogs only */
  }
  
  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }
  
  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }
  
  d-title {
    padding-top:5rem;
  }
  
  d-title p {
     font-size: 1rem; 
  }
  
  p {
    margin-bottom: 0;
  }
  
  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.5);
    /*margin-top: 5px;
    padding-top:30px;*/
  }
  
  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */
  
  .distill-site-header {
    --title-size:       18px;
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }
  
  .distill-site-footer {
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }
  
  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */
  
  .study {
    background-color: white;
    padding: 2%;
    margin: 2%;
    border: 2px solid;
    border-radius: 2px;
    box-shadow: 5px 2.5px 2.5px darkgrey;
  }
  
  .intro_box {
    background-color: white;
    padding: 2%;
    margin: 1%;
    border: 2px solid;
    border-radius: 2px;
    box-shadow: 5px 2.5px 2.5px darkgrey;
    font-size:0.8rem;
    line-height: 1.1rem;
  }
  
  .modalDialog {
  	position: fixed;
  	font-family: Arial, Helvetica, sans-serif;
  	top: 0;
  	right: 0;
  	bottom: 0;
  	left: 0;
  	background: rgba(0,0,0,0.8);
  	z-index: 99999;
  	opacity:0;
  	-webkit-transition: opacity 400ms ease-in;
  	-moz-transition: opacity 400ms ease-in;
  	transition: opacity 400ms ease-in;
  	pointer-events: none;
  }
  
  .modalDialog:target {
  	opacity:1;
  	pointer-events: auto;
  }
  
  .modalDialog > div {
  	width: 60vw;
  	position: relative;
  	margin: 10% auto;
  	padding: 5px 20px 13px 20px;
  	border-radius: 5px;
  	background: #fff;
  }
  
  .close {
  	background: #fff;
  	color: #FFFFFF;
  	line-height: 25px;
  	position: absolute;
  	float: right;
  	right: 10px;
  	text-align: right;
  	top: 12px;
  	width: 24px;
  	text-decoration: none;
  	border-bottom: none;
  	color: black!important;
  	/*font-weight: bold;*/
  	/*-webkit-border-radius: 12px;
  	-moz-border-radius: 12px;
  	border-radius: 12px;
  	-moz-box-shadow: 1px 1px 3px #000;
  	-webkit-box-shadow: 1px 1px 3px #000;
  	box-shadow: 1px 1px 3px #000;*/
  }
  
  .close:hover { border-bottom:none!important; }
  
  .copy-button {
    width:200px;
    font-size:1.2rem;
    margin-left:auto;
    cursor: pointer;
  }
  
  d-appendix a {
    color: #004276!important;
  }
  d-article a {
    color: #004276!important;
  }
  
  .help-me {
    border: 1px solid transparent;
    border-radius: 4px;
    border-color: #ccc;
    background-color: #cccccc40;
    padding: 2%;
    margin: 2%;
  }
  .help-me:hover {
    background-color: #cccccc90;
  }
  
  .btn{
      display: inline-block;
      width: 280px;
      padding: 2%;
      height: 10vh;
      margin: 10px;
      font-size: 20px;
      font-weight: 400;
      line-height: 5vh;
      text-align: center;
      white-space: nowrap;
      vertical-align: middle;
      -ms-touch-action: manipulation;
      touch-action: manipulation;
      cursor: pointer;
      -webkit-user-select: none;
      -moz-user-select: none;
      -ms-user-select: none;
      user-select: none;
      background-image: none;
      border: 1px solid transparent;
      border-radius: 4px;
      text-decoration: none;
      color: #333;
      background-color: #fff;
      border-color: #ccc;
  }
  
  .btn:hover{
    background:#cccccc50;
  }
  
  .cols {
    display: flex;
    align-items: center;
    justify-content:center;
  }
  
  @media (max-width: 1000px) {
    .cols {
      flex-direction: column;
    }
  
  }
  </style>
  <style type="text/css">
  /* base style */
  
  /* FONT FAMILIES */
  
  :root {
    --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }
  
  body,
  .posts-list .post-preview p,
  .posts-list .description p {
    font-family: var(--body-font), var(--body-default);
  }
  
  h1, h2, h3, h4, h5, h6,
  .posts-list .post-preview h2,
  .posts-list .description h2 {
    font-family: var(--heading-font), var(--heading-default);
  }
  
  d-article div.sourceCode code,
  d-article pre code {
    font-family: var(--mono-font), var(--mono-default);
  }
  
  
  /*-- TITLE --*/
  d-title h1,
  .posts-list > h1 {
    color: var(--title-color, black);
  }
  
  d-title h1 {
    font-size: var(--title-size, 50px);
  }
  
  /*-- HEADERS --*/
  d-article h1,
  d-article h2,
  d-article h3,
  d-article h4,
  d-article h5,
  d-article h6 {
    color: var(--header-color, rgba(0, 0, 0, 0.8));
  }
  
  /*-- BODY --*/
  d-article > p,  /* only text inside of <p> tags */
  d-article > ul, /* lists */
  d-article > ol {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
    font-size: var(--body-size, 1.06rem);
  }
  
  
  /*-- CODE --*/
  d-article div.sourceCode code,
  d-article pre code {
    font-size: var(--code-size, 14px);
  }
  
  /*-- ASIDE --*/
  d-article aside {
    font-size: var(--aside-size, 12px);
    color: var(--aside-color, rgba(0, 0, 0, 0.6));
  }
  
  /*-- FIGURE CAPTIONS --*/
  figure .caption,
  figure figcaption,
  .figure .caption {
    font-size: var(--fig-cap-size, 13px);
    color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
  }
  
  /*-- METADATA --*/
  d-byline h3 {
    font-size: var(--heading-size, 0.6rem);
    color: var(--heading-color, rgba(0, 0, 0, 0.5));
  }
  
  d-byline {
    font-size: var(--body-size, 0.8rem);
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }
  
  d-byline a,
  d-article d-byline a {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }
  
  /*-- TABLE OF CONTENTS --*/
  .d-contents nav h3 {
    font-size: var(--heading-size, 18px);
  }
  
  .d-contents nav a {
    font-size: var(--contents-size, 13px);
  }
  
  /*-- APPENDIX --*/
  d-appendix h3 {
    font-size: var(--heading-size, 15px);
    color: var(--heading-color, rgba(0, 0, 0, 0.65));
  }
  
  d-appendix {
    font-size: var(--text-size, 0.8em);
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }
  
  d-appendix d-footnote-list a.footnote-backlink {
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }
  
  /*-- WEBSITE HEADER + FOOTER --*/
  .distill-site-header .title {
    font-size: var(--title-size, 18px);
    font-family: var(--navbar-font), var(--heading-default);
  }
  
  .distill-site-header a,
  .nav-dropdown .nav-dropbtn {
    font-family: var(--navbar-font), var(--heading-default);
  }
  
  .nav-dropdown .nav-dropbtn {
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    font-size: var(--text-size, 15px);
  }
  
  .distill-site-header a:hover,
  .nav-dropdown:hover .nav-dropbtn {
    color: var(--hover-color, white);
  }
  
  .distill-site-header {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }
  
  .distill-site-footer {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }
  
  .distill-site-footer a:hover {
    color: var(--hover-color, white);
  }</style>
  <!--/radix_placeholder_distill-->
  <script src="site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <script type="text/javascript" src="https://www.cookieconsent.com/releases/3.1.0/cookie-consent.js"></script>
  <script type="text/javascript">
  document.addEventListener('DOMContentLoaded', function () {
  cookieconsent.run({
  'notice_banner_type':'simple',
  'consent_type': 'implied',
  'palette': 'light',
  'language': 'en/de/fr/es/ca_es/it/nl/pt/fi/hu/cs/hr/da/sl/pl/ro/sr/bg/cy',
  'website_name': 'aphasia-tech-map',
  
  'change_preferences_selector':'#CookiePreferences'
  });});</script>
  <script type="text/plain" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=G-K27Y5EDCX3"></script>
  <script type="text/plain" cookie-consent="tracking">
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-K27Y5EDCX3');
  </script>
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Aphasia research studies","authors":[]}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="index.html" class="title">Aphasia Tech Map</a>
</div>
<div class="nav-right">
<a href="index.html">Home</a>
<a href="table_view.html">Table</a>
<a href="list_view.html">Projects</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Aphasia research studies</h1>

<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->

</div>


<div class="d-article">
<p><link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"></p>
<div class="layout-chunk" data-layout="l-body">
<style type="text/css">
d-article{
  padding-bottom:20px;
  padding-top: 20px;
}
table td{ 
  word-break: break-all;
}

d-article li {
    margin-bottom: 0em;
}

d-article li:last-child {
    margin-bottom: 0.2em;
}

.name {
   font-size: 1.5rem;
  font-weight: bold;
  color: #0f5c81;
  margin: 1rem auto;
}

</style>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body-outset">
<br/>
<div id="1" class="study">
<div class="name">
VESFA (Virtual Elaborated Semantic Feature Analysis)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Niamh Devane, Katerina Hilari, Jane Marshall &amp; Stephanie Wilson
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:niamh.devane.1@city.ac.uk" class="email">niamh.devane.1@city.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, UK
</div>
<strong>Funding Source:</strong>
<div class="Location">
Doctoral studentship from the School of Health Sciences, City, University of London
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Virtual reality
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The VESFA trial was a single-blind, phase II feasibility randomised controlled trial comparing usual care + elaborated semantic feature analysis delivered remotely in a virtual environment called EVA Park with a usual care control. Feasibility outcomes of this trial explored recruitment and retention, willingness to be randomised, compliance with and acceptability of the treatment and of the outcome measures. A range of outcome measures were used that explored word finding in picture naming and discourse, functional communication, language, mood and quality of life.
</div>
<p><br/></p>
</div>
<br/>
<div id="2" class="study">
<div class="name">
KeyPhone
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Victoria Fleming, Wendy Best, Wei Ping Sze, and team
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:w.best@ucl.ac.uk" class="email">w.best@ucl.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, UK and Singapore
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Awaiting collaboration
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Use of orthographic cues in intervention with people with anomia.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Proof of concept was established in the 1980s by Carolyn Bruce, David Howard and team. This tech project builds on this and the results of a recent meta-analysis (Sze et al. 2021).
May also be categorised as AAC for some users. If there are others working on something similar, please get in touch.
</div>
</div>
<br/>
<div id="3" class="study">
<div class="name">
Swaracharya
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Nisheeth Joshi, Pragya Katyayan, Chitvan Mishra, Shefali Gupta
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:nisheeth.joshi@rediffmail.com" class="email">nisheeth.joshi@rediffmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Banasthali, India
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The project helps in rehab of Aphasia patients who have difficulty in speaking. The system has brain training module for this. Since almost 80% stokes occurs in rural India, the existing tools become useless for such patients or their care-givers. This system helps by providing brain training via Web and Mobile Interfaces in their local language.
</div>
<p><br/></p>
</div>
<br/>
<div id="4" class="study">
<div class="name">
Face to face and telehealth equivalence of assessments in aphasia (FATE-A)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Professor Katerina Hilari (Lead), Dr Nick Behn, Dr Sarah Northcott, Dr Abi Roper, Dr Niamh Devane, Amanda Comer, Jaycie Bohan. External collaborators: Dr Hortensia Gimeno, Dr Annie Hill, Dr Silia Vitoratou.
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:k.hilari@city.ac.uk" class="email">k.hilari@city.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
Phase 1 of the project is funded by City St George’s, University of London. Phase 2 and 3 are funded by Barts Charity.
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Other
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The aims of the project are to: 1. Explore barriers and facilitators to the telehealth administration of key measures for people with aphasia post-stroke. (Phase 1) 2. Determine the equivalence of face-to-face and telehealth administration of these measures. (Phase 2) 3. Develop a toolkit of resources and training for clinicians to help with the implementation of telehealth assessment and outcome measurement. (Phase 3)
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
This project involves a psychometric study, qualitative research, user testing, and development of a toolkit of resources for online / via telehealth assessment and outcome measurement in aphasia. At the end of the project findings will be directly implementable to clinical practice.
</div>
<em>Publications or resources:</em>
<div class="Location">
<p>Hilari K., Roper A., Northcott S., Behn N. (2023) Assessment in aphasia via telehealth: a survey of UK Speech and Language Therapy practice. International Journal of Language and Communication Disorders <a href="https://doi.org/10.1111/1460-6984.12996" class="uri">https://doi.org/10.1111/1460-6984.12996</a></p>
Comer A., Northcott S., Behn N., Roper A., Devane N., Hilari K. (2025) Experiences and perspectives of UK speech and language therapists on telehealth assessment with people living with post‐stroke aphasia. International Journal of Language and Communication Disorders. <a href="https://doi.org/10.1111/1460-6984.70018" class="uri">https://doi.org/10.1111/1460-6984.70018</a>
</div>
</div>
<br/>
<div id="5" class="study">
<div class="name">
Analyzing Communication Environments (ACE)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Jennifer Mozeiko, PI; Louisa Suting, PhD student; 2 MA students; 10 undergraduate students
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:jennifer.mozeiko@uconn.edu" class="email">jennifer.mozeiko@uconn.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Storrs, CT, USA
</div>
<strong>Funding Source:</strong>
<div class="Location">
American Speech Language Hearing Foundation (ASHF)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), It is also specific hardware (LENA devices)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Understand variables contributing to an “enriched” communicative environment to optimize rehabilitation.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We are using technology to collect, process, and analyze language data.
</div>
</div>
<br/>
<div id="6" class="study">
<div class="name">
Characterizing inner speech in aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Brielle Stark, Julianne Alexander (PhD student), team from NEURAL Research Lab at Indiana University
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:bcstark@iu.edu" class="email">bcstark@iu.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Bloomington IN, USA
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIDILRR Switzer Merit Fellowship
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Explore the extent to which individuals with aphasia experience inner speech, and further characterize this phenomenon. We use experience sampling methods via a smartphone (push notification) or SMS (text) to do this.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We have intentions of creating a specific smartphone app to evaluate this phenomenon after this exploratory phase.
</div>
<em>Publications or resources:</em>
<div class="Location">
Preprint: <a href="https://osf.io/gbw3t/" class="uri">https://osf.io/gbw3t/</a>
</div>
</div>
<br/>
<div id="7" class="study">
<div class="name">
“Shabdchitr”: ILAT Digital Application (Hindi, English, and other Indian languages
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
<ol type="1">
<li>Apoorva Pauranik. neurologist. 2. Pinky Singh, SLP. 3. N Sundaer, Computer Professional.
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:apauranik@gmail.com" class="email">apauranik@gmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Indore,India, India
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Shabdchitr is a Card Matching game based rehabilitation module to improve Speech – language and reading interaction skills. It works as a group therapy tool for SLP’s. Shabdchitr application is available as an executable (.exe) format on windows platform.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Salient features: 1. Expandable and scalable, i.e. a large number and variety of stimuli and playlists can be added and edited by the end users. 2. One SLP as an admin and upto four persons with aphasia and dyslexia/alexia can play the game across the internet. 3. The performance scores ( reaction times, error rates, error types) of participants are displayed in tabular and graphic formats over mutple sessions
</div></li>
</ol>
</div>
<br/>
<div id="8" class="study">
<div class="name">
A Digital compendium of Hindi-English Bilingual Home based Exercises for PWA.
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
<ol type="1">
<li>Apoorva Pauranik, Neurologist. 2. Pinky Singh, SLP. 3. Soubhik Das , Computer Professional
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:apauranik@gmail.com" class="email">apauranik@gmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Indore,India, India
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
<ol type="1">
<li>To create and make widely available a large and expandacle and scalable collection of diverse Home Based Exercises for Persons with Aphasia. 2, To eneble record keeping and report generation of the performance by the client.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Salient Features: 1. The computer professional will be providing a logical framework, wherein the clinicians as end-users will have many opprtunities to add and edit more stimuli and more types of exercises.2. The Home Based exercises are meant to be delivered by trained communication partners under supervision of SLP,. 3. The application will have facility for record keeping, score card and report generation across many sessions and many exercises.4. the exercises are based on cognitive neuropsychological model of spoken and written language, but also cover many pragmatic aspects
</div></li>
</ol></li>
</ol>
</div>
<br/>
<div id="9" class="study">
<div class="name">
INCA (inclusive digital content for people with aphasia)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Stephanie Wilson, Jane Marshall, Madeline Cruice, Abi Roper, Timothy Neate
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:s.m.wilson@city.ac.uk" class="email">s.m.wilson@city.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, UK
</div>
<strong>Funding Source:</strong>
<div class="Location">
Engineering and Physical Sciences Research Council + City, University of London
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To research and prototype digital technologies that will support people with aphasia in creating and curating digital content
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
No concrete plans for commercialisation, just exploring possibilities at present. See also <a href="https://blogs.city.ac.uk/inca/" class="uri">https://blogs.city.ac.uk/inca/</a>
</div>
</div>
<br/>
<div id="10" class="study">
<div class="name">
PNT-CAT: Computer Adaptive forms of the Philadelphia Naming Test
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Robert Cavanaugh, Alexander Swiderski, Stacey Steele, William D. Hula, Gerasimos Fergadiotis
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:rob.cavanaugh@pitt.edu" class="email">rob.cavanaugh@pitt.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Pittsbugh PA, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIH NIDCD
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Disseminate a free, open-source computer adaptive version of the PNT for clinical and research use.
</div>
<p><br/></p>
</div>
<br/>
<div id="11" class="study">
<div class="name">
Smart-phone assisted langauge training (SaLT)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
PhD thesis: Mr. Rajath shenoy, Guide: Dr. Gopee Krishnan, Dr. Lyndsey Nickels
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:rajaths1995@gmail.com" class="email">rajaths1995@gmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Manipal, Udupi, India
</div>
<strong>Funding Source:</strong>
<div class="Location">
Indian council of medical research (ICMR) Government of India (GOI)- Project title: Mixed reality in aphasia rehabilation (MiRaR)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
PhD research on development and validation for people with aphasia in multilingual environment
</div>
<p><br/></p>
</div>
<br/>
<div id="12" class="study">
<div class="name">
Pupillometry and eyetracking to index cognitive and linguistic processing in people with aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Laura Chapman, Mohammad Haghighi
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:bhallowell@springfield.edu" class="email">bhallowell@springfield.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Phoenixville, PA, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
Foundation funding now, previously NIH
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Assessment
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Harnessing the power of the eyes to reveal abilities and challenges not captured through typical assessment processes
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Please change contact email to: <a href="mailto:brookehallowell12@gmail.com" class="email">brookehallowell12@gmail.com</a>
</div>
<em>Publications or resources:</em>
<div class="Location">
See ResearchGate
</div>
</div>
<br/>
<div id="13" class="study">
<div class="name">
M-MAT Tele
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
John E Pierce, Miranda Rose, Dana Wong, Rachelle Pitt, Annie Hill, David Copland, Emma Power, Erin Godecke, Hannah Johns, Jemma Tulloch, Joosup Kim, Julie Adam, Tim Adam, Leanne Togher, Leonid Churilov, Marcella Carragher, Miranda Rose, Rob Nicholls, Ruth Townsend, Sam Harvey, Sandy Barry
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:j.pierce@latrobe.edu.au" class="email">j.pierce@latrobe.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Melbourne, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
La Trobe University, Stroke Foundation, MRFF
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Adapt and provide evidence for Multi-Modality Aphasia Therapy through telehealth
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
<p>M-MAT Tele: A digital adaptation of Multi-Modality Aphasia Therapy (M-MAT), co-designed with speech pathologists and people with aphasia to support group-based, moderate-intensity language rehabilitation via telehealth. Delivered over 30 hours, M-MAT Tele is designed for accessibility across rural and urban settings and is compatible with all major video platforms.</p>
<p>The intervention incorporates daily home practice, peer interaction, and a structured maintenance phase to enhance long-term outcomes. A pilot trial (n=9) confirmed feasibility and acceptability (manuscript in prep); a larger Phase II trial (n=72) is currently underway to evaluate efficacy and cost-effectiveness.</p>
Resources—including software, manuals, and training materials—are being prepared for open-access dissemination to support clinical implementation.
</div>
<em>Publications or resources:</em>
<div class="Location">
<p>www.mmat.rehab</p>
Development paper: <a href="https://www.tandfonline.com/doi/full/10.1080/17483107.2024.2366423" class="uri">https://www.tandfonline.com/doi/full/10.1080/17483107.2024.2366423</a>
</div>
</div>
<br/>
<div id="14" class="study">
<div class="name">
Personalising dose in cued picture naming treatment
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Sam Harvey, Miranda Rose, Michael Walsh Dickey, Marcella Carragher
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:sam.harvey@uq.edu.au" class="email">sam.harvey@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Melbourne, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To investigate dose-response relationships in cued picture naming treatment
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
<p>We built a web-app that allows a clinician to set up online cued picture naming therapy sessions. Functions include adding users (PWA), adding assets (pictures, audio files for verbal cues) and linking assets, selecting and allocating pictures to stimulus sets, and adjusting the amount of time the person with aphasia has to respond to cues throughout treatment. The experimental set up also allows for probe sessions and pre- and post-session subjective ratings of fatigue, motivation and task difficulty. The web-app can produce reports about sessions (timing data, subjective ratings response data, items probed/treated, etc) in excel/csv format.</p>
Future plans include expanding web-app (items, users), allowing independent practice (free-use), and adding speech recognition to support independent practice.
</div>
<em>Publications or resources:</em>
<div class="Location">
<a href="https://www.tandfonline.com/doi/full/10.1080/02687038.2022.2144112" class="uri">https://www.tandfonline.com/doi/full/10.1080/02687038.2022.2144112</a>
</div>
</div>
<br/>
<div id="15" class="study">
<div class="name">
VA11y (Videoconference Accessibility)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Timothy Neate, Stephanie Wilson
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:timothy.neate@kcl.ac.uk" class="email">timothy.neate@kcl.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery), Virtual reality, Augmentative and Alternive Communication, communication accessibility (e.g. text to speech feature), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To design more accessible videoconference technologies for those with language impairments.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
<p>We are human-computer interaction researchers who work closely with SLTs and co-design technologies with people with aphasia. We have recently completed research which investigates the specific communication challenges faced by people with aphasia when videoconferencing. This is to be published at CHI 2022 [1]. We are currently working developing a project which will leverage recent technological innovations to complement videoconference, and support more effective total communication.</p>
[1] - <a href="https://kclpure.kcl.ac.uk/portal/files/166216025/chi_no_copyright.pdf" class="uri">https://kclpure.kcl.ac.uk/portal/files/166216025/chi_no_copyright.pdf</a>
</div>
</div>
<br/>
<div id="16" class="study">
<div class="name">
Integrating complementary learning principles in aphasia rehabilitation via adaptive modeling
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
William Evans, William Hula, Jeff Starns, Peter Brusilovsky
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:will.evans@pitt.edu" class="email">will.evans@pitt.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Pittsburgh, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIH NIDCD
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery), Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Increase the functional impact of established aphasia treatment by combining the benefits of complementary learning approaches through adaptive timing models
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Submitting on behalf of Dr. Evans.
</div>
</div>
<br/>
<div id="17" class="study">
<div class="name">
Measuring, Monitoring, and Motivating Adherence to Self-Managed Aphasia Treatment
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
CIA A/Prof Sarah Jane Wallace The University of Queensland
CIB Prof David A Copland The University of Queensland
CIC Prof Janet Wiles The University of Queensland
CID Assoc Prof Anthony J Angwin The University of Queensland
CIE Assoc Prof Victoria Jane Palmer University of Melbourne
CIF Dr Peter Harold Worthy The University of Queensland
CIG Dr Anne Jane Hill The University of Queensland
CIH Dr Barbra H. B. Timmer The University of Queensland
CII Assoc Prof Matthew John Gullo The University of Queensland
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:s.wallace3@uq.edu.au" class="email">s.wallace3@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Brisbane, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
MRFF Cardiovascular Mission
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Generic software (e.g. dictation software already available), Augmentative and Alternative Communication, communication accessibility (e.g. text to speech feature), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
We aim to empower stroke survivors with aphasia to successfully self-manage their long-term recovery through co-design, development, and evaluation of a novel mobile health smartphone application that motivates adherence to real-life, self-managed Comprehensive, High-dose Aphasia Treatment.
</div>
<p><br/></p>
</div>
<br/>
<div id="18" class="study">
<div class="name">
Zooming Great
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
FIRLE Beckley, Kate Whiteman
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:firle@sayaphasia.org" class="email">firle@sayaphasia.org</a>
</div>
<strong>Country:</strong>
<div class="Location">
Eastbourne, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
Through local community grants
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Improving social connectedness using tech
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To pilot whether we can get people with aphasia independently using zoom
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
This is a small scale pilot being carried out by FIRLE in her role within a charity called Say Aphasia
</div>
</div>
<br/>
<div id="19" class="study">
<div class="name">
LAST-App for Acute Stroke
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Heather Flowers, Laura Monetta, Constance Flamand-Roze, Miguel Garzon, Susie Williams
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:heather.flowers@uottawa.ca" class="email">heather.flowers@uottawa.ca</a>
</div>
<strong>Country:</strong>
<div class="Location">
Ottawa, Canada, Canada
</div>
<strong>Funding Source:</strong>
<div class="Location">
From a local research institute
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To Undertake Beta Testing and Implement a Training Platform of a New Health-Tech Application for the Language Screening Test (called LAST-App)
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Our app is based on the Language Screening Tool (LAST) developed for English (harmonized for Canadian, American, British, and Australian English) and French (European and Canadian French). The LAST-App is compatible with android, iOS, and web-based platforms (thanks to a year-long collaboration with software engineers). We are still seeking new international collaborations, but plan to undertake beta testing in Canada (with our grant funding).
</div>
</div>
<br/>
<div id="20" class="study">
<div class="name">
The development of an application compatible with mobile device to support language, cognition, communication for clients with neurological language disorders
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
<p>Tolga Sözüçok (A Study for the requirement PhD / Doctoral Dissertation)</p>
İlknur Maviş
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:Tolgasozucok@gmail.com" class="email">Tolgasozucok@gmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Eskişehir/ Turkey , Turkey
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
to develop an application for auditory comprehension problems for for clients with neurological language disorders
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
It was a phd dissertation we aim to publish it as article soon.
</div>
</div>
<br/>
<div id="21" class="study">
<div class="name">
PeerPAL- Digital Networking in Aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Project management: Prof. Dr. Norina Lauer &amp; Prof. Dr. Sabine Corsten; research assistants: Christina Kurfess, Maren Nickel, Daniel Kreiter
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:norina.lauer@oth-regensburg.de" class="email">norina.lauer@oth-regensburg.de</a>
</div>
<strong>Country:</strong>
<div class="Location">
Regensburg &amp; Mainz, Germany
</div>
<strong>Funding Source:</strong>
<div class="Location">
Federal Ministry of Education and Research (BMBF)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Improve quality of life by conneting people with aphasia
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
<a href="http://www.peerpal.de/en/" class="uri">http://www.peerpal.de/en/</a>
</div>
<em>Publications or resources:</em>
<div class="Location">
Kurfess, C., Corsten. S., Nickel, M., Knieriemen, M., Kreiter, D. &amp; Lauer, N. (2023). Peer-to-peer support: digital network-ing in aphasia to improve quality of life (PeerPAL) - study protocol for app development and evaluation. Frontiers in Communication, 8, 1187233. <a href="https://doi.org/10.3389/fcomm.2023.1187233" class="uri">https://doi.org/10.3389/fcomm.2023.1187233</a>
</div>
</div>
<br/>
<div id="22" class="study">
<div class="name">
Aphasia iCafè interview project: Student-delivered online social support groups for people with aphasia and/or dysarthria- a qualitative investigation of members’ and providers’ experiences
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr Anna Caute, Annabel Kay, Erika Mangialardi
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:anna.caute@essex.ac.uk" class="email">anna.caute@essex.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
Colchester, UK
</div>
<strong>Funding Source:</strong>
<div class="Location">
British Aphasiology Society Initiatives in Aphasia Seed Fund grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The project will address the following questions: • What are the views of people with aphasia and/or dysarthria about taking part in student-delivered online social support groups? • What are the views of student speech and language therapists (SLTs) about delivering online social support groups for people with aphasia and/or dysarthria? • What facilitators or barriers did they experience? • What was the impact of taking part for people with aphasia/dysarthria and student SLTs?
</div>
<p><br/></p>
</div>
<br/>
<div id="23" class="study">
<div class="name">
KoLiPENs - Kognitive, linguistische und personenbezogene Einflussfaktoren auf das Schreiben (Cognitive, linguistic and personal factors influencing writing)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Albrecht, Katharina; Jaecks, Petra; Jonas, Kristina; Stegenwallner-Schütz, Maja; von Lehmden, Friederike
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:petra.jaecks@uni-bielefeld.de" class="email">petra.jaecks@uni-bielefeld.de</a>
</div>
<strong>Country:</strong>
<div class="Location">
Cologne, Germany
</div>
<strong>Funding Source:</strong>
<div class="Location">
Third-party funding
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
not yet finally decided
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The long-term goal of the KoliPENs project is to develop a digital diagnostic procedure for the area of written language in neurological writing disorders which a) covers the levels of the ICF (function, activity, participation), b) covers analogue as well as digital writing competences and c) covers written language discourse skills.
</div>
<p><br/></p>
</div>
<br/>
<div id="24" class="study">
<div class="name">
Mixed reality in aphasia rehabilation (MiRaR)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr. Gopee Krishnan, Dr. Shivani Tiwari, Dr. Apoorva Pauranik, Dr. Aparna Pai, Mr. Rajath Shenoy, Mr Intiaz, Ms Sona
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:krishnan.g@manipal.edu" class="email">krishnan.g@manipal.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Manipal, India
</div>
<strong>Funding Source:</strong>
<div class="Location">
Indian council of medical research , Government of India
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Virtual reality
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
to develop and clinical validated the newly developed Mixed reality application for persons with aphasia
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Google form submitted by Mr.Rajath Shenoy on behalf of Dr. Gopee Krishnan, Manipal college of health professions, India
</div>
</div>
<br/>
<div id="25" class="study">
<div class="name">
Therapy calculator for rehabilitation outcomes after acquired brain injury
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr. Swathi Kiran; Dr. Margrit Betke; Dr. Prakash Ishwar; Dr. Claire Cordella
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:cordella@bu.edu" class="email">cordella@bu.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Boston, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
Internal institutional funds
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To use machine learning methods to predict recovery trajectory profiles following rehabilitation for ABI individuals with chronic disability
</div>
<p><br/></p>
</div>
<br/>
<div id="26" class="study">
<div class="name">
Assessing Communication and Clinical Effectiveness of Self-managed Speech-language therapy: a randomized control trial of a novel digital therapeutic in individuals with post-stroke aphasia (ACCESS)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr. Swathi Kiran; Dr. Steven Cramer; Dr. Maria Varkanitsa
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:cordella@bu.edu" class="email">cordella@bu.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Boston, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To examine if a self-managed, at-home, personalized, and comprehensive (i.e., targeting multiple language domains) CT program will lead to greater language-based recovery gains compared to usual care and an active control
</div>
<p><br/></p>
</div>
<br/>
<div id="27" class="study">
<div class="name">
Virtual Groups and Computerized Therapy for Primary Progressive Aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Jessica D. Richardson, H. Isabel Hubbard, Christie Duhigg, Jordyn Sims
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:jdrichardson@unm.edu" class="email">jdrichardson@unm.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Albuquerque, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To determine the feasibility and preliminary efficacy of weekly virtual group meetings and daily computerized therapy for communication and life participation in persons with primary progressive aphasia
</div>
<p><br/></p>
</div>
<br/>
<div id="28" class="study">
<div class="name">
The impact of home-based computer therapy to improve speech and cognitive function during stroke recovery
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Janet Alexander MSPH; Patricia Zrelak PhD RN; Michelle Camicia PhD RN FAHA; Brian Theodore PhD; Kam Gardner CCC-SLP; Diana Storti MS CCC-SLP; Linda Heckenlively MS, CCC-SLP; Melissa Meighan DNP MS RN; Mai N Nguyen-Huynh MD MAS
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:jordyn.pierce@constanttherapy.com" class="email">jordyn.pierce@constanttherapy.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Walnut Creek, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
Constant Therapy Health/The Learning Corp
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Identify cost-savings options for patients with aphasia, e.g., utilizing digital therapeutics to reduce in-clinic visits
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Technology is already commercialized
</div>
</div>
<br/>
<div id="29" class="study">
<div class="name">
Development of a Free Online Interactive Naming Therapy for Bilingual Aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Chaleece Sandberg, Teresa Gray, Swathi Kiran
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:cws18@psu.edu" class="email">cws18@psu.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
University Pk, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
American Speech-Language- Hearing Association Projects on Multicultural Activities grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The purpose of this ongoing project was to provide speech-language pathologists who serve culturally and linguistically diverse populations with a freely available online tool for naming therapy in a variety of languages.
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<a href="https://doi.org/10.1044/2019_AJSLP-19-0035" class="uri">https://doi.org/10.1044/2019_AJSLP-19-0035</a>
</div>
</div>
<br/>
<div id="30" class="study">
<div class="name">
Social-ABI-lity
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Liss Brunner, Rachael Rietdijk, Emma Power, Melissa Miao, Petra Avramovic, Leanne Togher
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:leanne.togher@sydney.edu.au" class="email">leanne.togher@sydney.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
icare NSW
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Promote safe use of social media for people with ABI
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<p><a href="https://abi-communication-lab.sydney.edu.au/courses/social-abi-lity/" class="uri">https://abi-communication-lab.sydney.edu.au/courses/social-abi-lity/</a></p>
<p>Brunner, M., Hemsley, B., Togher, L., Dann, S., &amp; Palmer, S. (2021). Social media and people with traumatic brain injury (TBI): A meta-synthesis of research informing a framework for rehabilitation clinical practice, policy, and training, American Journal of Speech Language Pathology, 30 (1), 19-33, doi: 10.1080/09638288.2019.1685604</p>
<p>Brunner, M., Togher, L., Palmer, S., Dann, S. &amp; Hemsley, H. (2021). Rehabilitation professionals’ views on social media use in traumatic brain injury rehabilitation. Disability and Rehabilitation, 43 (14), 1955-1964 doi: 10.1080/09638288.2019.1685604</p>
<p>Brunner, M., Rietdijk, R., &amp; Togher, L. (2022). Training resources targeting social media skills: A scoping review to inform rehabilitation for people who have an acquired brain injury. Journal of Medical Internet Research, Apr 28;24(4):e35595.doi: 10.2196/35595.</p>
Brunner, M., Rietdijk, R., Summers, K., Southwell, K., Avramovic, P., Power, E., Miao, M., Rushworth, N., LacLean, L., Brookes, A. &amp; Togher, L. (2022). It gives you encouragement because you’re not alone”: A pilot study of a multi-component social media skills intervention for people with acquired brain injury. International Journal of Language and Communication Disorders, 23 November 2022, <a href="https://doi.org/10.1111/1460-6984.12806" class="uri">https://doi.org/10.1111/1460-6984.12806</a>
</div>
</div>
<br/>
<div id="31" class="study">
<div class="name">
interact-ABI-lity
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leanne Togher, Rachael Rietdijk, Emma Power, Petra Avramovic, Melissa Miao, Liss Brunner
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:leanne.togher@sydney.edu.au" class="email">leanne.togher@sydney.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
icare NSW
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Communication partner training and education
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<a href="https://abi-communication-lab.sydney.edu.au/courses/interact-abi-lity/" class="uri">https://abi-communication-lab.sydney.edu.au/courses/interact-abi-lity/</a>
</div>
</div>
<br/>
<div id="32" class="study">
<div class="name">
Convers-ABI-lity
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leanne Togher, Rachael Rietdijk, Emma Power, Melissa Brunner, Melissa Miao, Petra Avramovic
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:leanne.togher@sydney.edu.au" class="email">leanne.togher@sydney.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
icare NSW
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To improve conversations of people with acquired brain injury
</div>
<p><br/></p>
</div>
<br/>
<div id="33" class="study">
<div class="name">
Virtual reality for social communication
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leanne Togher, Sophie Brassel, Emma Power, Andrew Campbell, Liss Brunner
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:leanne.togher@sydney.edu.au" class="email">leanne.togher@sydney.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Virtual reality
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To develop virtual reality assessment scenarios for social communication
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<p>Brassel, S., Brunner, M., Power, E., Campbell, A., &amp; Togher, L. (2023). Speech-language pathologists’ views of using virtual reality for managing cognitive-communication disorders following traumatic brain injury, American Journal of Speech Language Pathology, 2S, 907-923, doi: 10.1044/2022_AJSLP-22-00077. Epub 2022 Dec 29</p>
Brassel, S., Power, E., Campbell, A., Brunner, M., &amp; Togher, L. (2021). Recommendations for the design and implementation of virtual reality for acquired brain injury rehabilitation: Systematic Review. Journal of Medical Internet Research, 23, (7), e26344, doi: 10.2196/26344
</div>
</div>
<br/>
<div id="34" class="study">
<div class="name">
Communication partner training for health professional students
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leanne Togher, Michelle Attard, Emma Power, Rachael Rietdijk, Lucy Lanyon
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:leanne.togher@sydney.edu.au" class="email">leanne.togher@sydney.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
NHMRC CRE Aphasia
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To provide communication partner training to students in health related fields
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
Power, E., Attard, M., Lanyon, L. &amp; Togher, L. (2024). Efficacy of online communication partner training package for student health professionals, International Journal of Language and Communication Disorders, 59 (1), 304-326 Open Access, 10.1111/1460-6984.12947
</div>
</div>
<br/>
<div id="35" class="study">
<div class="name">
Phase III Development of a Valid, Reliable, Clinically Feasible Measure of Transactional Success in Aphasic Conversation: Modernizing Methods of Acquisition and Analysis of Discourse Data
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Jacquie Kurland, Polly Stokes, Anna Liu, Brendan O’Connor, Vishnupriya Varadharaju
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:jacquie@umass.edu" class="email">jacquie@umass.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Amherst, MA, U.S.
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIDCD R21
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
A combination of telehealth delivery and natural language processing (including some machine learning tools) for data analysis
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
There are two specific aims, both of which involve technology in aphasia rehabilitation research. In developing a tool that can be used to assess transactional success in conversation, we are evaluating the use of natural language processing tools to automatically transcribe and analyze discourse text. In addition, all of the testing will be delivered remotely.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We have completed data acquisition, have a paper in press on the tool’s reliability and are drafting a paper on it’s validity. Since the advent of generative AI tools, we have also been investigating how to leverage large language models to assist with the analysis of story retelling discourse.
</div>
<em>Publications or resources:</em>
<div class="Location">
<p>Kurland, J., Liu, A., Varadharaju, V, Stokes, P., &amp; Cavanaugh, R. (in press, Aphasiology). Reliability of the Brief Assessment of Transactional Success in Communication in Aphasia. <a href="https://dx.doi.org/10.1080/02687038.2024.2351029" class="uri">https://dx.doi.org/10.1080/02687038.2024.2351029</a></p>
Kurland, J, Varadharaju, V, Stokes, P, &amp; Liu, A. Preliminary Testing of Large Language Models’ Ability to Assess Main Concepts in Story Retelling: A Comparison of Human vs. Machine Ratings of Main Concepts. To be presented at Clinical Aphasiology Conference, May 2024. Waikoloa Beach, HI.
</div>
</div>
<br/>
<div id="36" class="study">
<div class="name">
Communication Bridge: A person-centered Internet-based intervention for individuals with primary progressive aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Emily Rogalski, PhD, Angela Roberts, Phd, Alfred Rademaker, PhD, Darby Morhardt, PhD
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:e-rogalski@northwestern.edu" class="email">e-rogalski@northwestern.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Chicago, IL, USA
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIA R01
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
RCT
</div>
<p><br/></p>
</div>
<br/>
<div id="37" class="study">
<div class="name">
Remote administration of Combined Aphasia and Apraxia of Speech Treatment (CAAST)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Julie Wambaugh, Lydia Kallhoff
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:julie.wambaugh@health.utah.edu" class="email">julie.wambaugh@health.utah.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Salt Lake City, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Powerpoint
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To evaluate the effects of CAAST administered remotely
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
Accepted for publication in the American Journal of Speech-Language Pathology
</div>
</div>
<br/>
<div id="38" class="study">
<div class="name">
“Lets talk” app for smartphone
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Merav Raveh Malka
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:merav.raveh@gmail.com" class="email">merav.raveh@gmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Jerusalem, Israel
</div>
<strong>Funding Source:</strong>
<div class="Location">
Thru a non profit organization called Ezer Metzion
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase IV - Effectiveness
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Augmentative and Alternative Communication, communication accessibility (e.g. text to speech feature)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To transfer the low tech communication aids with highly accessible high tech easy to use phone app
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
The app is being prepared in hebrew and Arabic. It is being developed by HILMA - high tech for the good of society. The app will be free to use. I am really excited to share it with the world and looking forward to hear about new technologies around the world!!
</div>
</div>
<br/>
<div id="39" class="study">
<div class="name">
Sentactics
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Elena Barbieri
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:ckthom@northwestern.edu" class="email">ckthom@northwestern.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Chicago, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIH
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase IV - Effectiveness
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Discontinued
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Treatment of sentence processing impairments in aphasia.
</div>
<p><br/></p>
</div>
<br/>
<div id="40" class="study">
<div class="name">
Assessment of anomia: Improving efficiency and utility using item response theory
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
WIlliam D. Hula, Gerasimos Fergadiotis, Michael Walsh Dickey, Daniel Taylor-Rodriguez, Miranda Babiak, Hannele Nicholson, Cheralyn Ranjan, Stacey Steel, Andrew Womack
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:gf3@pdx.edu" class="email">gf3@pdx.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Pittsburgh, PA; Portland, OR., United States of America
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIH/NIDCD R01DC018813
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Framework that can be used for a range of assessment purposes.
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Develop a suite of psychometric tools for the assessment of anomia.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Given that this project is focused on assessment, the “Phases of research” do not align well.
Currently, our primary goals are to (i) disseminate a computer adaptive version of the Philadelphia Naming Test; (ii) develop a universal metric of anomia, linking multiple published tests, and (iii) create a computer adaptive test with hundreds of items for the assessment of both object and action naming.
</div>
<em>Publications or resources:</em>
<div class="Location">
<p>Casilio., M., Fergadiotis, G., Cho, S. J., Steel, S., Fleegle, M., Dickey, M. W., &amp; Hula, D. W. (2025). Construct validation of the verb naming test for aphasia. Journal of Speech, Language, and Hearing Research, 68(4), 1932-1949</p>
<p>Fergadiotis, G., Casilio, M., Steel, S., Fleegle, M., Dickey, M., &amp; Hula, W. (2023). Item response theory modeling of the Verb Naming Test. Journal of Speech, Language, and Hearing Research.</p>
Fergadiotis, G., Casilio, M. Hula, W., &amp; Swiderski, A. (2021). Computer adaptive testing for the assessment of anomia severity. Seminars in Speech and Language, 42, 180-191. <a href="https://doi.org/10.1055/s-0041-1727252" class="uri">https://doi.org/10.1055/s-0041-1727252</a>.
</div>
</div>
<br/>
<div id="41" class="study">
<div class="name">
Automatic Classification of Paraphasias
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Steven Bedrick; Gerasimos Fergadiotis; Alexandra Salem; Robert Gale; Mikala Fleegle
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:gf3@pdx.edu" class="email">gf3@pdx.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Portland, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The aims include: (i) develop a series of NLP algorithms for automatically classifying paraphasias in the context of confrontation naming tests and discourse; (i) automatically identify paraphasias in connected speech; and (iii) predict the intended production of a person with aphasia when they produce a paraphasia.
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<p>Gale, R., Salem, A., Fleegle, M., Fergadiotis, G., &amp; Bedrick, S. (accepted). Mixed Orthographic/Phonemic Language Modeling: Beyond Orthographically Restricted Transformers (BORT). Proceedings of the RepL4NLP, ACL 2023.</p>
<p>Casilio, M., Fergadiotis, G., Salem, A., Gale, R., McKinney-Bock, K., &amp; Bedrick, Steven. (2023). ParAlg: A paraphasia algorithm for multinomial classification of picture naming errors. Journal of Speech, Language, and Hearing Research, 66(3), 966-986. DOI: 10.1044/2022_JSLHR-22-00255</p>
<p>Salem. A., Gale, R., Casilio, M., Fleegle, M., Fergadiotis, G., &amp; Bedrick, S. (2023). Refining semantic similarity of paraphasias using a contextual language model. Journal of Speech, Language, and Hearing Research, 66(1), 206-220. DOI: 10.1044/2022_JSLHR-22-00277.</p>
<p>Gale. R., Fleegle, M., Fergadiotis, G., &amp; Bedrick, S. (2022). The post-stroke speech transcription (PSST) challenge. Proceedings of the RaPID-4, LREC 2022, 41-55.</p>
<p>Adams, J., Bedrick, S., Fergadiotis, G., Gorman, K., and van Santen, J. (2017). Target word prediction and paraphasia classification in spoken discourse. In Proceedings of the BioNLP Workshop, 1-8.</p>
Fergadiotis, G., Gorman, K., &amp; Bedrick, S. (2016). Algorithmic classification of five characteristic types of paraphasias. American Journal of Speech-Language Pathology, 25, S776-S787. <a href="DOI:10.1044/2016_AJSLP-15-0147" class="uri">DOI:10.1044/2016_AJSLP-15-0147</a>
</div>
</div>
<br/>
<div id="42" class="study">
<div class="name">
Automatic Speech Recognition for Aphasic Speech
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Robert Gale, Gerasimos Fergadiotis, Steven Bedrick, Mikala Fleegle
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:gf3@pdx.edu" class="email">gf3@pdx.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Portland OR, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To develop an automatic speech recognition system for automatic transcription of aphasic speech in the context of confrontation naming applications and connected speech.
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
Gale. R., Fleegle, M., Fergadiotis, G., &amp; Bedrick, S. (2022). The post-stroke speech transcription (PSST) challenge. Proceedings of the RaPID-4, LREC 2022, 41-55.
</div>
</div>
<br/>
<div id="43" class="study">
<div class="name">
Home-based language therapy and transcranial direct current stimulation in pri-mary progressive aphasia.
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Meinzer, Flöel, Grewe, Binkofski
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:marcus.meinzer@med.uni-greifswald.de" class="email">marcus.meinzer@med.uni-greifswald.de</a>
</div>
<strong>Country:</strong>
<div class="Location">
Greifswald, Germany
</div>
<strong>Funding Source:</strong>
<div class="Location">
German Federal Ministry for Education and Research
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Concept development phase completed; funding for implementation phase has been requested
</div>
<strong>Category:</strong>
<div class="Location">
technology adapation (brain stimulation)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
We aim to facilitate access to effective treatments for patients with PPA by using technological aids that will allow us to treat the patients remotely, in their own homes (for details see comment below)
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We will adapt a highly effective language therapy and brain stimulation program, developed by our group, in such a way that it can be executed via a tablet computer and a mobile brain stimulation device under close remote supervision by a therapist. The core of the program is a computer-based naming therapy, that will be combined with a training of communication strategies relevant for everyday life. A trained speech therapist will provide treatment via the internet. We will also work with the manufacturer of the brain stimulation device, to make it easy and comfortable for patients or their carers to administer the stimulation. The project has two main goals: (1) first, we will repeatedly consult with patients, their carers and patient advocacy groups to identify specific needs and potential barriers with regard to how assessments and therapy will be conducted. This information will be used to optimize the existing treatment program for home-based use and patients with primary progressive aphasia. (2) Subsequently, we will implement and test the procedures and technology in a small group of patients in their homes to find out how well their needs and wishes have been considered and make further adjustments, if necessary. With this iterative process, we aim to enhance adherence to this novel treatment program, its effectiveness and ultimately patient benefit.
</div>
<em>Publications or resources:</em>
<div class="Location">
<p>Rysop A.U., Schiwek R., Grewe T., Breitenstein C., Binkofski F., Roheger M., Unger N., Flöel A., Meinzer M. (in press) Participatory development of speech-language telerehabilitation combined with home-based transcranial direct current stimulation for primary progressive aphasia. American Journal of Speech Language Pathology preprint: doi.org/10.1101/2024.12.10.24318315</p>
Rysop A.U., Grewe T., Breitenstein C., Binkofski F., Roheger M., Unger N., Flöel A., Meinzer M. Feasibility of home-based transcranial direct current stimulation with telerehabilitation in primary progressive aphasia – a case series. preprint: doi.org/10.31234/osf.io/rw5v2_v1
</div>
</div>
<br/>
<div id="44" class="study">
<div class="name">
Modulating stimulus intensity to improve clinical outcomes in aphasia treatment (MIDAS)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leora Cherney and Sarel van Vuuren (MPI)
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:Lcherney@sralab.org" class="email">Lcherney@sralab.org</a>
</div>
<strong>Country:</strong>
<div class="Location">
Chicago, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIH - R01 (5 years)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
An RCT to investigate stimulus repetition and stimulus distribution as factors that modulate dose and intensity of treatment.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
The goal is not to assess the technology - but we are using the technology to facilitate the study. As we have written in the grant - we use a script treatment (AphasiaScripts) that has experimental support regarding its efficacy, and that allows the manipulation of the two variables under study, stimulus practice distribution and stimulus repetition. To ensure independence and fidelity, treatment is provided in a controlled computer environment (desktop and tablet). To avoid clinician-related variables such as expertise and personality factors that may influence treatment, sentences are modeled during treatment by an anthropomorphic agent with high visual speech intelligibility and affective expressions.
</div>
</div>
<br/>
<div id="45" class="study">
<div class="name">
Improving electronic written communication in persons with aphasia: A clinical trial
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leora Cherney (PI).
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:Lcherney@sralab.org" class="email">Lcherney@sralab.org</a>
</div>
<strong>Country:</strong>
<div class="Location">
Chicago, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
3 year federal grant from NIDILRR (National Institute on Disability, Independent Living, and Rehabilitation Research)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Aims are to: 1) evaluate the efficacy of computer-based texting treatment for improving written communication in persons with aphasia and 2) assess the extent to which improvements in electronic written communication impact social connectedness and health-related quality of life (HRQOL).
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
The computer software in this study is an expansion of our ORLA treatment that adds a writing component - which has then been further adapted to target texting
</div>
</div>
<br/>
<div id="46" class="study">
<div class="name">
Timing of transcranial direct current stimulation (tDCS) combined with speech and language therapy (SLT) : An Intervention Development Study for Aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leora Cherney, Sameer Ashaie
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:Lcherney@sralab.org" class="email">Lcherney@sralab.org</a>
</div>
<strong>Country:</strong>
<div class="Location">
Chicago, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
Federal grant from NIDILRR (3 year grant)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery), tDCS (brain stimulation technology)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To conduct a randomized clinical trial in individuals with aphasia that compares the differential effects of tDCS delivered prior to, concurrent with, and following SLT.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Use of technology is two-fold: 1) tDCS and 2) the aphasia treatment that is provided before, during or after the tDCS, is provided by ciomputer and is AphasiaScripts.
</div>
</div>
<br/>
<div id="47" class="study">
<div class="name">
N/A - there are technology tools that we are using across multiple projects to measure outcomes
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Leora Cherney, Sameer Ashaie
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:Lcherney@sralab.org" class="email">Lcherney@sralab.org</a>
</div>
<strong>Country:</strong>
<div class="Location">
Chicago, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
Projects may or may not be funded - but we have exploratory aims for objectively measuring relevant behaviors
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Measurement tools
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To identify novel ways to measure behaviors in the lab and in the real world environment
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Across various treatment studies, we are exploring the use of eye tracking, heart rate variability, laryngeal sensors, GPS, EEG, and resting state MRI as measures of change from pre to post treatment.
</div>
</div>
<br/>
<div id="48" class="study">
<div class="name">
Communication Access and Participation Through Immersive Virtual and Augmented Reality Technologies (CAPTIVATE)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Lucy Bryant, Bronwyn Hemsley, Emma Power, et al.
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:lucy.bryant@uts.edu.au" class="email">lucy.bryant@uts.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
To date, through seed grants and internal grant funding at the University of Technology Sydney (Graduate School of Health Seed Grant, UTS ECR Development Grant, Faculty of Health Mentoring Grant)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery), Virtual reality
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The project aims to design, develop, and evaluate immersive VR and AR applications that enable adults with aphasia to practice their communication skills for social and occupational interactions. The project plan is to design and implement virtual reality (VR) and augmented reality (AR) to improve communication access, and social and economic participation.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Others have been involved across various stages and arms of this research, including: UTS researchers (Peter Stubbs (physio), Vincent Nguyen (orthoptics), Benjamin Bailey (speech pathology), Andrew Bluff (visualization and animation)); UTS Masters of Speech Pathology students (Neira Sedlarevic, Henry Keegan, Clarisse Baker), and expert reference group members from industry, UTS, and NSW Health.
</div>
</div>
<br/>
<div id="49" class="study">
<div class="name">
VoiceAdapt: Voice Adaptive Training for Older Adults with Aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Esther Kim (University of Alberta); Elizabeth Rochon (University of Toronto)
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:esther.kim@ualberta.ca" class="email">esther.kim@ualberta.ca</a>
</div>
<strong>Country:</strong>
<div class="Location">
Edmonton, Toronto, Canada
</div>
<strong>Funding Source:</strong>
<div class="Location">
Joint Programming Initiative - More Years Better Lives
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The purpose of the VoiceAdapt project is to develop and test the efficacy of an app designed using principles of User Centered Design (UCD) on the lexical retrieval abilities of people with aphasia.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Other consortium members based in Germany (Technical University Berlin; Nurogames - Cologne) and Austria (Austrian Institute of Technology)
</div>
<em>Publications or resources:</em>
<div class="Location">
Kim, E. S., Laird, L., Wilson, C., Bieg, T., Mildner, P., Möller, S., … &amp; Rochon, E. (2021). Implementation and Effects of an Information Technology–Based Intervention to Support Speech and Language Therapy Among Stroke Patients With Aphasia: Protocol for a Virtual Randomized Controlled Trial. JMIR Research Protocols, 10(7), e30621. <a href="https://doi.org/10.2196/30621" class="uri">https://doi.org/10.2196/30621</a>
</div>
</div>
<br/>
<div id="50" class="study">
<div class="name">
TeleCHAT
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Annie, Hill, Genevieve Vuong, Jade Dignam, Clare Burns, David Copland
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:aj.hill@uq.edu.au" class="email">aj.hill@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Brisbane, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
QARC and initial support from CRE Aphasia
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Telerehabilitation delivered through Zoom
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To investigate the usability, feasibility, acceptability and effectivelness of delivering CHAT via telerehabilitation (TeleCHAT)
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
TeleCHAT uses Zoom to delivery this ICAP. A wide range of tech features within Zoom are utilised to maximise participation of PWA and places most of the technology burden on the SLP.
</div>
</div>
<br/>
<div id="51" class="study">
<div class="name">
CHAT-Maintain: Maintaining language and quality of life gains with low-dose technology-delivered aphasia therapy
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Jade Dignam, David Copland, Annie Hill, Miranda Rose, Deborah Hersh, Kirstine Shrubsole, John Pierce, Sarah J. Wallace, Emma Power, Kate O’Brien, Kat Roxas, Emma O’Neill, Kylie Short, Penni Burfein, Jessica Campbell (†).
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:j.dignam@uq.edu.au" class="email">j.dignam@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Brisbane, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
Stroke Foundation Lady Marigold Southey Aphasia Research Grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Aim 1: To evaluate CHAT-Maintain’s potential efficacy in maintaining language, functional communication and quality of life outcomes at 3 and 6 months post intensive treatment and feasibility. Aim 2: To evaluate the potential impact of CHAT-Maintain on communication activity, social participation, and communication confidence. Aim 3: To collaborate with people with aphasia and family members to iteratively improve CHAT-maintain.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Recruitment for this study has closed. Data analysis is underway.
</div>
</div>
<br/>
<div id="52" class="study">
<div class="name">
Aphasia Tech Quest
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Jessica Campbell, Kori Ramajoo, Sarah J. Wallace, Sonia Brownsett, Peter Worthy, Jacki Liddle, Ciara Shiggins, Lisa Anemaat, David Copland
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:jessica.campbell@uq.edu.au" class="email">jessica.campbell@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Brisbane, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
School of Health and Rehabilitation Sciences: ART Hub project
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Platform
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
<ol type="1">
<li>Develop and describe a model collaborative design process involving people with aphasia, clinicians, technologists and researchers which may be used more broadly in rehabilitation sciences in future. 2. Explore person with aphasia experience of a collaborative design process, particularly accessibility of the event, aspects of co-production (e.g. perceived equality between participants and equal opportunity to decide goals and outcomes), opportunities for social connection, and likelihood of engaging in future collaborations. 3. Explore clinician, technologist and researcher experience of collaborative design process, particularly capacity to collaborate with people with aphasia in future. 4. Explore a collaborative design process as a way of increasing public awareness of aphasia within and externally to UQ.
</div>
<br/></li>
</ol>
</div>
<br/>
<div id="53" class="study">
<div class="name">
Technology access service priorities of people with aphasia, significant others, and healthcare providers
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Annie Hill, Sonia Brownsett, Kori Ramajoo, Jessica Campbell, Sarah J. Wallace, Jade Dignam, Kirstine Shrubsole, Peter Worthy, Jacki Liddle, David Copland,
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:s.brownsett@uq.edu.au" class="email">s.brownsett@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Brisbane, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Phase I: This phase aims to determine consumer priorities for services that would support access to technology in a sample of Queensland people with aphasia, significant others of people with aphasia, and healthcare providers treating people with aphasia. Phase 2: This phase aims to investigate consumer priorities more closely by exploring individual goals of people with aphasia related to accessing technology to work on communication or life participation goals, determine individual consumer preferences for receiving technology-related services, and understand the acceptability and goal attainment outcomes of receiving support, advice and consultation from a speech pathologist and/or supervised speech pathology students.
</div>
<p><br/></p>
</div>
<br/>
<div id="54" class="study">
<div class="name">
HealthTalk Connect
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Miranda Rose, Marcella Carragher, Robyn O’Halloran, Edwina Lamborn, Lauren Fletcher
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:m.rose@latrobe.edu.au" class="email">m.rose@latrobe.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Melbourne, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
La Trobe University Research Support Grant and Epworth Health Foundation grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To develop and test an app aimed at improving healthcare communication in hospital
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We have completed proof of concept testing within 2 Australian health networks. We are exploring commercialisation opportunities.
</div>
<em>Publications or resources:</em>
<div class="Location">
We have several manuscripts in draft.
</div>
</div>
<br/>
<div id="55" class="study">
<div class="name">
Aphasia App - Community
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Miranda Rose, Robyn O’Halloran, Kylie Casey
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:m.rose@latrobe.edu.au" class="email">m.rose@latrobe.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Melbourne, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
We have a grant application under review
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To develop and test an app aimed at improving healthcare communication in the community for people with aphasia
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
Casey, K., O’Halloran, R., Vandenberg, M., &amp; Rose, M.L. (2023). We got there in the end…somehow, we got there": A qualitative study of healthcare professionals providing care in the community to people with chronic aphasia, and how technology could assist. Disability and Rehabilitation, 46(16), 3681-3690, <a href="https://doi.org/10.1080/09638288.2023.2256666" class="uri">https://doi.org/10.1080/09638288.2023.2256666</a>
</div>
</div>
<br/>
<div id="56" class="study">
<div class="name">
Communication Connect
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Miranda Rose, Damminda Alahakoon, Ian Kneebone, Brooke Ryan, Emma Power, Annie Hill, Leanne Togher, Tim Usherwood, David Copland, Richard Lindley, John E Pierce…
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:communication.connect@latrobe.edu.au" class="email">communication.connect@latrobe.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Melbourne, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
National Health and Medical Research Council Ideas Grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To develop and test applications of artificial intelligence to support people living with aphasia in the long-term.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Communication Connect is a comprehensive online platform containing self-management resources, education, carer support, training and intervention resources for three key user groups – people with communication disability (from stroke or brain injury), carers, and health professionals working with this population. Communication Connect is underpinned by an artificial intelligence-enabled data management and resources platform.
We co-designed Communication Connect with key groups including:
1. people with lived experience of communication disability,
2. family/carers,
3. health professionals including general practitioners, healthcare staff and policy makers from three sites (Bendigo, Brisbane and Sydney)
Co-designers shared challenges of discharge, rehabilitation and long-term management of communication disability from stroke and brain injury before prioritising 15 challenges for Communication Connect to target. Communication Connect contains three portals with resources for these three groups.
</div>
<em>Publications or resources:</em>
<div class="Location">
twitter.com/CommunConnect
</div>
</div>
<br/>
<div id="57" class="study">
<div class="name">
Social Brain Toolkit
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Professor Leanne Togher, Dr Rachael Rietdijk, Professor Emma Power, Dr Melissa Brunner, Dr Petra Avramovic, Dr Sophie Brassel
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:rachael.rietdijk@sydney.edu.au" class="email">rachael.rietdijk@sydney.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
icare NSW
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To develop and pilot online resources aimed at supporting more successful interactions after acquired brain injury
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<p>LINK TO RESOURCES:
<a href="https://abi-communication-lab.sydney.edu.au/social-brain-toolkit/" class="uri">https://abi-communication-lab.sydney.edu.au/social-brain-toolkit/</a></p>
<p>PUBLICATIONS:</p>
<p>Avramović, P., Rietdijk, R., Kenny, B., Power, E., &amp; Togher, L. (2023). Developing a digital health intervention for Conversation Skills After Brain Injury (convers-ABI-lity) using a collaborative approach: mixed methods study. Journal of Medical Internet Research, 25, e45240. <a href="https://doi.org/10.2196/45240" class="uri">https://doi.org/10.2196/45240</a></p>
<p>Brunner, M., Rietdijk, R., Summers, K., Southwell, K., Avramovic, P., Power, E., Miao, M., Rushworth, N., MacLean, L., Brookes, A-M., Togher, L. (2022). “It gives you encouragement because you’re not alone”: A pilot study of a multi-component social media skills intervention for people with acquired brain injury. International Journal of Language and Communication Disorders. Advance online publication. <a href="https://doi.org/10.1111/1460-6984.12806" class="uri">https://doi.org/10.1111/1460-6984.12806</a></p>
<p>Brunner, M., Rietdijk, R., Power, E., Avramovic, P., Miao, M., Rushworth, N., MacLean, L., Brookes, A-M., Togher, L. (2022). Developing social-ABI-lity: an online course to support safe use of social media for connection after brain injury. American Journal of Speech-Language Pathology. Advance online publication. <a href="https://doi.org/10.1044/2022_AJSLP-22-00099" class="uri">https://doi.org/10.1044/2022_AJSLP-22-00099</a></p>
<p>Miao, M., Power, E., Rietdijk, R., Debono, D., Brunner, M., Salomon, A., Mcculloch, B., Wright, M.R., Welsh, M., Tremblay, B., Rixon, C., Williams, L., Morrow, R., Evain, J., &amp; Togher, L. (2022). Coproducing knowledge of the implementation of complex digital health interventions for adults with acquired brain injury and their communication partners: Protocol for a mixed methods study. JMIR Research Protocols, 11(1), e35080. <a href="https://doi.org/10.2196/35080" class="uri">https://doi.org/10.2196/35080</a></p>
<p>Miao, M., Power, E., Rietdijk, R., Togher, L., Brunner, M., &amp; Debono, D. (2021). A web-based service delivery model for communication training after brain injury: Protocol for a mixed methods, prospective, hybrid type 2 implementation-effectiveness study. JMIR Research Protocols, 10(12), e31995. <a href="https://doi.org/10.2196/31995" class="uri">https://doi.org/10.2196/31995</a></p>
Miao, M., Power, E., Rietdijk, R., Brunner, M., Togher, L., &amp; Debono, D. (2021). The Social Brain Toolkit: Implementation considerations from the development of a suite of novel online social communication training programs for adults with acquired brain injury and their communication partners. Journal of Clinical Practice in Speech-Language Pathology, 23(2), 75-80. 
</div>
</div>
<br/>
<div id="58" class="study">
<div class="name">
WRITE-IT
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr Celia Woolf (Project Lead) and Co-investigators Dr Madeline Cruice and Morganie Naidoo
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:m.cruice@city.ac.uk" class="email">m.cruice@city.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
LONDON, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
School Pump Priming Grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
WRITE-IT will explore feasibility of delivering technology-enhanced group therapy for writing impairments after stroke remotely over Zoom.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We start in August 2022 for 12 months. The project is small scale recruiting N=8 people with aphasia.
</div>
</div>
<br/>
<div id="59" class="study">
<div class="name">
MARS: ROJECT: Exploring initial feasibility of MARS: A LUNA-TherapyBox collaboration MARS: Machine learning Analysis and Reporting of Spoken personal stories
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr Madeline Cruice, Dr Lucy Dipper, Rebecca Bright, Swapnil Gudgil
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:m.cruice@city.ac.uk" class="email">m.cruice@city.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
LONDON, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
Health Education England internal university Participatory Research Funding call
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
the aims of this small-scale participatory research project are to: 1. scope speech therapists’ interest and demand in MARS for patients with aphasia across the stroke rehabilitation pathway (acute, inpatient, early supported discharge, and community) 2. explore speech therapists’ potential uses of and training needs in using MARS 3. identify the likely benefits of MARS to speech therapists and the indirect benefit to clients with aphasia (i.e., reduces barriers to discourse work and so they will do it more); and 4. explore the perspectives (reactions and opinions) of stroke survivors with aphasia (and potentially family members) to using MARS
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
MARS is a small scale (£5k) collaboration between LUNA at City, University of London and TherapyBox. TherapyBox has developed an automated system for recording, transcribing, and analysing typical and atypical speech in children with language disorder [see <a href="https://www.languageexplorer.app/" class="uri">https://www.languageexplorer.app/</a>], which has easy transferable application to atypical speech in adults with aphasia. This application is referred to as MARS and would incorporate the specific LUNA discourse analyses as well as explore stakeholders’ additional ideas. The LUNA-TherapyBox collaboration brings together expertise in machine learning, general and specialist UX with this clinical population, theoretical and applied clinical linguistics, and current knowledge of national therapist practice and behaviour.
</div>
</div>
<br/>
<div id="60" class="study">
<div class="name">
Strategies to Accommodate Reading in Aphasia: Using Assistive Technology to Support Reading by People with Aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Kelly Knollman Porter, Sarah E. Wallace, Karen Hux, Jessica Brown
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:sarah.wallace@pitt.edu" class="email">sarah.wallace@pitt.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Pittsburgh, PA, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIDCD 1R15DC015579-01A1
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Our goal is to test the effectiveness of using and adjusting key TTS features to help people with aphasia independently read everyday texts of interest and value to them.
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<ol type="1">
<li><p>Knollman-Porter, K., Bevelhimer, A., Hux, K., Wallace, S.E., Hughes, M., Brown., J. (2023). Eye fixation behaviors and processing time of people with aphasia and neurotypical adults when reading narratives with and without text-to-speech support. Journal of Speech-Language-Hearing Research, 66(1), 276-295. doi: 10.1044/2022_JSLHR-22-00298</p></li>
<li><p>Knollman-Porter, K., Hux, K., Wallace, S. E., Pruitt, M., Hughes, M. R., &amp; Brown, J. A. (2022). Comprehension, processing time, and modality preferences when people with aphasia and neurotypical healthy adults read books: A Pilot Study. American Journal of Speech-Language Pathology, 31(6), 2569-2590. <a href="https://doi.org/10.1044/2022_AJSLP-22-00121" class="uri">https://doi.org/10.1044/2022_AJSLP-22-00121</a></p></li>
<li><p>Wallace, S.E., Patterson, J., Knollman-Porter, K., Purdy, M., &amp; Coppens, P. (2022) (2023). Auditory comprehension treatment for aphasia: A scoping review. American Journal of Speech-Language Pathology, 31(5S), 2404-2420. doi: 10.1044/2022_AJSLP-21-00297</p></li>
<li><p>Knollman-Porter, K.P., Brown, J., Hux, K., Wallace, S.E., &amp; Crittenden, A. (2022). Reading comprehension and processing time when people with aphasia use text-to-speech technology with personalized supports and features. American Journal of Speech-Language Pathology, 31(1), 342-358. <a href="https://doi.org/10.1044/2021_ajslp-21-00182" class="uri">https://doi.org/10.1044/2021_ajslp-21-00182</a></p></li>
<li><p>Wollersheim, M., Brown, J.A., Hux, K., Knollman-Porter, K., &amp; Wallace, S.E. (2021). Effects of repeated exposure to synthetic and digitized natural speech by individuals with aphasia. Perspectives of the ASHA Special Interest Groups, 6(3), 581–595. <a href="https://doi.org/10.1044/2021_persp-20-00211" class="uri">https://doi.org/10.1044/2021_persp-20-00211</a></p></li>
<li><p>Wallace, S.E., Hux, K., Knollman-Porter, K., Brown. J.A., Parisi, E., &amp; Cain, R. (2021). Reading behaviors and text-to-speech technology perceptions of people with aphasia. Assistive Technology, 34(5), 599-610. <a href="https://doi.org/10.1080/10400435.2021.1904306" class="uri">https://doi.org/10.1080/10400435.2021.1904306</a></p></li>
<li><p>Hux, K., Wallace, S.E., Brown, J.A., &amp; Knollman-Porter, K. (2021). Perceptions of people with aphasia about supported reading with text-to-speech technology: A convergent mixed methods study. Journal of Communication Disorders, 91(May-June), 106098. doi: 10.1016/j.jcomdis.2021.106098</p></li>
<li><p>Brown, J.A., Knollman-Porter, K., Hux, K., Wallace, S.E., &amp; Deville, C. (2020). Effect of digital highlighting on reading comprehension given text-to-speech technology for people with aphasia. Aphasiology, 35(2), 200-221. <a href="https://doi.org/10.1080/02687038.2020.1787728" class="uri">https://doi.org/10.1080/02687038.2020.1787728</a></p></li>
<li><p>Hux, K., Brown, J., Wallace, S.E., Knollman-Porter, K., Saylor, A., &amp; Lapp, E. (2020). Effect of text-to-speech rate on reading comprehension by people with aphasia. American Journal of Speech-Language Pathology, 29(1), 168-184. <a href="https://doi.org/10.1044/2019_AJSLP-19-00047" class="uri">https://doi.org/10.1044/2019_AJSLP-19-00047</a></p></li>
<li><p>Knollman-Porter, K., Wallace, S.E., Brown, J.A., Hux, K., Hoagland, B.L., &amp; Ruff, D.R. (2019). Effects of written, auditory, and combined modalities on comprehension by people with aphasia. American Journal of Speech-Language Pathology, 28, 1206-1221.</p></li>
<li><p>Wallace, S.E., Knollman-Porter, K., Brown, J.A., &amp; Hux, K. (2019). Narrative comprehension by people with aphasia given single versus combined modality presentation. Aphasiology, 33, 731-754. doi: 10.1080/02687038.2018.1506088</p>
</div></li>
</ol>
</div>
<br/>
<div id="61" class="study">
<div class="name">
Improving Home Program Practice for People with Language Disorders after Stroke
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Elena Donoso Brown, Sarah E. Wallace, Jamie Lee
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:sarah.wallace@pitt.edu" class="email">sarah.wallace@pitt.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Pittsburgh, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
Faculty Development Fund (Internal Funding)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific app (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The purpose of the research is to understand how logbook recording affects home practice patterns of people with aphasia
</div>
<p><br/></p>
</div>
<br/>
<div id="62" class="study">
<div class="name">
Telepresence robots for the care and support of stroke patients (TePUS)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Prof. Dr. Karsten Weber, Prof. Dr. Sonja Haug, Prof. Dr. Norina Lauer, Prof. Dr. Christa Mohr, Prof. Dr. Andrea Pfingsten, Prof. Dr. Georgios Raptis, Edda Currle, Katrin Ettl, Dr. Debora Frommeld, Nina Greiner, Natalie Kudienko, Christof Popp, Anselm Stadler
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:norina.lauer@oth-regensburg.de" class="email">norina.lauer@oth-regensburg.de</a>
</div>
<strong>Country:</strong>
<div class="Location">
Regensburg, Germany
</div>
<strong>Funding Source:</strong>
<div class="Location">
Bavarian State Ministry of Health and Care
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
In this interdisciplinary project in the funding line “DeinHaus 4.0”, the home-based use of telepresence robots for care and therapy (speech and language therapy and physiotherapy) is being researched. The focus is on the improvement of quality of life, communication and mobility as well as the investigation of the acceptance of telepresence robots in the context of teletherapy.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
The project is carried out at the Regensburg Center of Health Sciences and Technology (RCHST) of the OTH Regensburg (2019-2023)
</div>
<em>Publications or resources:</em>
<div class="Location">
<a href="https://www.deinhaus40.de/start/" class="uri">https://www.deinhaus40.de/start/</a>
</div>
</div>
<br/>
<div id="63" class="study">
<div class="name">
<a href="https://www.tell-teletherapie.de/" class="uri">https://www.tell-teletherapie.de/</a> Konzeption und Entwicklung einer Plattform zur Telediagnostik und Teletherapie bei neurogenen Sprachstörungen – teletherapeutisches lebensgeschichtliches Erzählen zur Steigerung von Lebensqualität (TELL)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Prof.in Dr. Sabine Corsten, Catholic University of Apllied Sciences Mainz, Germany
Prof.in Dr. Juliane Leinweber, Hochschule für angewandte Wissenschaft und Kunst Hildesheim/Holzminden/Göttingen; Germany
Dr. Jürgen Keller, RELIMETRICS GmbH, Berlin, Germany
Farid Kanbari, POLAVIS GmbH, Berlin; Germany
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:sabine.corsten@kh-mz.de" class="email">sabine.corsten@kh-mz.de</a>
</div>
<strong>Country:</strong>
<div class="Location">
Berlin, Germany
</div>
<strong>Funding Source:</strong>
<div class="Location">
Federal Ministry of Education and Research
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Conception and development of a platform for teletherapy for telling life stories to increase
quality of life in aphasia
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Additional locations: Mainz, Göttingen
</div>
</div>
<br/>
<div id="64" class="study">
<div class="name">
APP4PPA: Online Speech-language Therapy in Italian individuals with Primary Progressive Aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Petronilla Battista, Stephanie Grasso, Maya Henry, Maria Luisa Gorno Tempini
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:petronilla.battista@gbhi.org" class="email">petronilla.battista@gbhi.org</a>
</div>
<strong>Country:</strong>
<div class="Location">
Bari, Italy
</div>
<strong>Funding Source:</strong>
<div class="Location">
Alzheimer’s Assocation, GBHI Pilot Awards
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
We aim to provide remote speech and language therapy to treat language impairment associated with Primary Progressive Aphasia (PPA). The purpose of this study is also to develop a new web-based platform that will assist Speech and Language therapists during individualized language intervention.
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/1460-6984.12843" class="uri">https://onlinelibrary.wiley.com/doi/full/10.1111/1460-6984.12843</a>
</div>
</div>
<br/>
<div id="65" class="study">
<div class="name">
Plug-In and Power-Up: Boosting Health Self-Efficacy through Communication-Accessible Online Environments
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Sarah Wallace, Peter Worthy, David Copland, Kirstine Shrubsole, Kim Barron, Phil Jamieson, Annie Hill, Janet Wiles, Alex Haslam, Jennifer Lee, Ryan Deslandes, Savita Datta
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:s.wallace3@uq.edu.au" class="email">s.wallace3@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Brisbane, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
UQ Foundation Research Excellence Awards
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To co-design a novel web plug-in that re-renders websites to make them accessible to people with communication disability.
</div>
<p><br/></p>
</div>
<br/>
<div id="66" class="study">
<div class="name">
Using a digital spelling aid to improve writing in persons with post-stroke aphasia: An intervention study
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr Charlotte Johansson Malmeling, Dr Malin Antonsson, Professor Åsa Wengelin
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:ingrid.henriksson@neuro.gu.se" class="email">ingrid.henriksson@neuro.gu.se</a>
</div>
<strong>Country:</strong>
<div class="Location">
Gothenburg, Sverige
</div>
<strong>Funding Source:</strong>
<div class="Location">
Swedish Research Council, The Swedish Stroke Foundation, The Swedish Aphasia Association
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Software developed for developmental reading- and writing difficulties
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The aim was to investigate what impact training to use a computerised
spell checker had on text writing in persons with aphasia.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
The software is commercially available
</div>
<em>Publications or resources:</em>
<div class="Location">
Johansson-Malmeling, C., Wengelin, Å., Antonsson, M. &amp; Henriksson, I. (2022). Using a digital spelling aid to improve writing in personswith post-stroke aphasia: An intervention study. International journal of language and communication disorders, available online DOI: 10.1111/1460-6984.12591
</div>
</div>
<br/>
<div id="67" class="study">
<div class="name">
Utilization of Immersive Virtual Reality in Computerized Script Training for People With Aphasia: A Feasibility Study
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr. Winsy Wong, Dr. Donald Li
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:winsywg@gmail.com" class="email">winsywg@gmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
Hong Kong SAR, China
</div>
<strong>Funding Source:</strong>
<div class="Location">
University internal funding
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Virtual reality
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To investigate the effects of immersive virtual reality in rehabilitation of language and communication of individuals with post-stroke aphasia
</div>
<p><br/></p>
</div>
<br/>
<div id="68" class="study">
<div class="name">
Evaluating the SpeechFirst therapy app
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Michael Dean
Hannah Harvey
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:michael.dean@ucl.ac.uk" class="email">michael.dean@ucl.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
Tech4PositiveFutures, Capgemini UK.
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Complete
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To evaluate acceptability and preliminary efficacy of a therapy application for remediation of spoken language deficits: ‘SpeechFirst.’ The app employs automatic speech recognition based in machine learning to provide feedback to the user on the accuracy of their responses. Exercises and materials are uploaded to each user’s device remotely, and results are accessible to the clinician remotely.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Study conducted at the UCL Communication Clinic, Department of Language and Cognition, University College London.
</div>
<em>Publications or resources:</em>
<div class="Location">
<p>Open source software (modelling resources, data collection tools and inference code):
<a href="https://github.com/Capgemini-AIE/speechfirst" class="uri">https://github.com/Capgemini-AIE/speechfirst</a></p>
Questionnaires for the evaluation of speech and language therapy apps:
<a href="https://doi.org/10.5522/04/21815877.v1" class="uri">https://doi.org/10.5522/04/21815877.v1</a>
</div>
</div>
<br/>
<div id="69" class="study">
<div class="name">
Bridging the Digital Divide: Building Health Self-Efficacy through Communication-Accessible Online Environments
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
A/Prof Sarah Wallace
Dr Peter Worthy
Prof David Copland
Phillip Jamieson
Kim Barron
Prof Leanne Togher
Dr Kirstine Shrubsole
Dr Anne Hill
Prof Janet Wiles
Prof Alex Haslam
Dr Jennifer Lee
Mr Ryan Deslandes
Ms Savita Datta
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:s.wallace3@uq.edu.au" class="email">s.wallace3@uq.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Brisbane, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
MRFF Consumer Led Research
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Generic software (e.g. dictation software already available), Augmentative and Alternative Communication, communication accessibility (e.g. text to speech feature), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
We will work in partnership with people living with aphasia, health professionals and our partner organisations to iteratively co-develop a novel multi-component intervention called CAP Pack (Communication Accessibility Plug-in Pack). CAP Pack will comprise: (1) CAP software that re-renders website content to meet individual communication requirements and supports information-seeking through a recommender system; (2) a decision-making tool and training package that supports health professionals to customise CAP and train people with aphasia to use it; and (3) Guidelines for communication-accessible website design that increase knowledge and awareness of communication-access needs.
</div>
<p><br/></p>
</div>
<br/>
<div id="70" class="study">
<div class="name">
<a href="http://www.aphasiatherapyonline.com/" class="uri">http://www.aphasiatherapyonline.com/</a>
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Özlem Oğuz, Memik Yıldız, John Pierce
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:ozlemoguz.gs@gmail.com" class="email">ozlemoguz.gs@gmail.com</a>
</div>
<strong>Country:</strong>
<div class="Location">
İstanbul, Turkiye
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The aim is to adapt and culturally adapt the Online Aphasia Therapy Program, which includes different activities for many language modalities such as listening, reading, writing and naming, with a focus on the ‘sequential cue approach’ used in the therapy of individuals with aphasia into Turkish.
</div>
<p><br/></p>
</div>
<br/>
<div id="71" class="study">
<div class="name">
The CogNeuro App: A Novel Web-Based App for Neuropsychological Assessment of Impairments of Language
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Britta Biedermann, Max Coltheart, Deborah Hersh, Lizz Hill, Steve Saunders
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:b.biedermann@curtin.edu.au" class="email">b.biedermann@curtin.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Perth/ Sydney, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
Tavistock Trust for Aphasia UK
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Other
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), This will be an assessment app accessible from Desktops, Laptops, Tablets and Mobiles.
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
<a href="https://aphasiatavistocktrust.org/projects/the-cogneuro-app-a-novel-web-based-app-for-neuropsychological-assessment-of-impairments-of-language/" class="uri">https://aphasiatavistocktrust.org/projects/the-cogneuro-app-a-novel-web-based-app-for-neuropsychological-assessment-of-impairments-of-language/</a>
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
<p>While we try not to commercialise this app as we are envisaging to create an Open Access Tool (following the Spirit of the Open Science Framework) - we may need to commercialise it in order to pay for its ongoing maintenance.</p>
Our vision at the moment is: The outcome of this project will be a co-designed OPEN ACCESS interactive clinical and teaching app that can be used in clinical settings and speech pathology curricula. It can be promoted freely to other educational institutions, nationally and internationally. It will also be a useful tool for students, clinical educators and clinicians in a range of language rehabilitation settings.
</div>
<em>Publications or resources:</em>
<div class="Location">
<a href="https://cogneuro.app/beta/" class="uri">https://cogneuro.app/beta/</a>
</div>
</div>
<br/>
<div id="72" class="study">
<div class="name">
Dynamic Assessment of Everyday Communication using Virtual Reality: proof of concept for persons with post-stroke aphasia (DCOM-VR)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Marina Ruiter, Vitoria Piai, Willemijn Doedens, and others
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:marina.ruiter@ru.nl" class="email">marina.ruiter@ru.nl</a>
</div>
<strong>Country:</strong>
<div class="Location">
Nijmegen, The Netherlands
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Virtual reality
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
Rationale: Current evidence suggests that one in four Dutch speakers lives with brain damage. For many, an accompanying acquired language disorder, i.e., aphasia, significantly affects their ability to communicate in day-to-day life and their participation in society. To guide them towards communicative independence, diagnostic instruments are needed that provide insight into the communicative difficulties that are experienced in the real world.
Objective: The goal of this project is to develop a VR tool for PWA that simulates daily communication. The VR tool allows simulation of realistic communicative interactions between a person and a computer-generated avatar, including both verbal and nonverbal behaviour. The assessment of communicative performance not only is ecologically valid, but also highly controlled. Factors such as the level of support provided by the conversation partner (I.e., computer-generated avatar), background noise, the speed of conversation, and amount of interruptions, can be manipulated.
</div>
<p><br/></p>
</div>
<br/>
<div id="73" class="study">
<div class="name">
A pilot-study into the effectiveness of therapeutic app SimpTell for speakers with chrnoaphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Marina Ruiter, Vitoria Piai, Ardi Roelofs
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:marina.ruiter@ru.nl" class="email">marina.ruiter@ru.nl</a>
</div>
<strong>Country:</strong>
<div class="Location">
Nijmegen, The Netherlands
</div>
<strong>Funding Source:</strong>
<div class="Location">
NA
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase III - Efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
This pilot-study investigates the effectiveness of SimpTell, a therapy app for people with aphasia. SimpTell is an acronym for Semi-independent Interactive Multimodal Production Training of ELLipses (in Broca’s aphasia). The app supports speech and language therapists (SLTs) in teaching Dutch-speaking persons with chronic Broca’s aphasia to produce reduced utterances (i.e., ellipses) to compensate for their sentence production difficulties. Ellipses resemble telegraphic style (e.g., ‘Stroke last year. Speaking difficult. Producing short sentences only’). The functional design of the app is based on the knowledge gained from previous research on executive control in compensatory language production (e.g., Roelofs, 2014; Piai et al., 2016) as well as studies into the (positive) effect of elliptical style on verbal functional communication (e.g., Ruiter et al., 2010; Ruiter et al., 2016).
</div>
<p><br/></p>
</div>
<br/>
<div id="74" class="study">
<div class="name">
Communication Bridge 3: A person-centered Internet-based intervention for individuals with primary progressive aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Emily Rogalski, PhD, Angela Roberts, PhD
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:matthew.bona@bsd.uchicago.edu" class="email">matthew.bona@bsd.uchicago.edu</a>
</div>
<strong>Country:</strong>
<div class="Location">
Chicago, United States
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIA R01
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
By conducting this study, we aim to identify optimal intervention strategies for supporting individuals living with primary progressive aphasia (PPA) and their communication partners.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We are located at the University of Chicago. This is a telehealth clinical trial conducted entirely virtually. No in-person sessions are necessary.
</div>
</div>
<br/>
<div id="75" class="study">
<div class="name">
HiSSS - Hybrid and interactive speech therapy after stroke
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Klaus Kugelmann, Speechcare GmbH; Laura Tuschen, Fraunhofer IDMT; Prof. Dr. Juliane Leinweber, Hochschule für angewandte Wissenschaft und Kunst Hildesheim/Holzminden/Göttingen; Rolf Behrens, Bitnamic GmbH
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:katharina.giordano@hawk.de" class="email">katharina.giordano@hawk.de</a>
</div>
<strong>Country:</strong>
<div class="Location">
Göttingen, Germany
</div>
<strong>Funding Source:</strong>
<div class="Location">
Federal Ministry of Education and Research (BMBF)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase I - Proof of concept
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Yes
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The project HiSSS aims to develop a hybrid &amp; interactive format for speech &amp; language therapy after stroke.
The core of the project is a web-based speech therapy care that integrates existing and innovative both synchronous and asynchronous therapeutic elements. The innovative elements include the automatic speech recognition (ASR) and automatic face recognition (AFR) via the sensors of the user device and the use of these analysis results in the therapy. All elements are part of a speech therapy interaction, which can be applied in face-to-face and video therapy, but also in asynchronous self-administered exercises.
</div>
<br/>
<em>Publications or resources:</em>
<div class="Location">
<a href="https://hisss.care/" class="uri">https://hisss.care/</a>
DOI: 10.1007/978-3-031-35897-5_39
</div>
</div>
<br/>
<div id="76" class="study">
<div class="name">
UTILISE-2: a digital intervention for sentence difficulties in aphasia
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Professor Rosemary Varley, Dr Claudia Bruns, Kerry Dathan, Fern Rodgers, Dr Victoria Fleming; Dr Amir H Javadi
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:rosemary.varley@ucl.ac.uk" class="email">rosemary.varley@ucl.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, UK
</div>
<strong>Funding Source:</strong>
<div class="Location">
Research funding via UK The Stroke Association. Technical development via the UCL Therapeutic Accelerator Scheme.
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To evaluate outcomes, dose-outcome relationships, and participant views on a digital sentence therapy app named UTILISE (Unification Therapy Integrating LexIcon and SEntences).
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
We will explore potential for commercialisation if preliminary efficacy and acceptability are established.
</div>
<em>Publications or resources:</em>
<div class="Location">
<ol type="1">
<li>ISRCTN entry with link to OSF protocol: <a href="https://www.isrctn.com/ISRCTN11888024" class="uri">https://www.isrctn.com/ISRCTN11888024</a></li>
<li>Lab webpage with video about the research made by The Stroke Association: <a href="https://www.cognitionandgrammar.net/utilise" class="uri">https://www.cognitionandgrammar.net/utilise</a></li>
<li>Case series report investigating an early form of UTILISE: Bruns, C., Beeke, S., Zimmerer, V., Bruce, C., &amp; Varley, R. (2019). Training flexibility in fixed expressions in non-fluent aphasia: A case series report. International Journal of Language and Communication Disorders, 56(5), 1009–1025. <a href="https://doi.org/10.1111/1460-6984.12652" class="uri">https://doi.org/10.1111/1460-6984.12652</a>
</div></li>
</ol>
</div>
<br/>
<div id="77" class="study">
<div class="name">
Optimising decision-making for aphasia therapy app use (OPTIMA)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr Vasiliki Kladouchou, Professor Katerina Hilari, Jaycie Bohan
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:Vasiliki.Kladouchou@citystgeorges.ac.uk" class="email">Vasiliki.Kladouchou@citystgeorges.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
SHPS Pump Priming Funding, City, University of London, UK
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
OPTIMA aims to: 1) investigate available aphasia apps by reviewing existing evidence and 2) to explore current app-based therapy practices, including selection criteria, usage patterns, and support mechanisms, by collecting new data from SLTs. The outcome of this analysis will be a decision-making framework for SLTs to effectively select and recommend aphasia apps for people with aphasia to use to promote their aphasia recovery. Groundwork activities for establishing a hub dedicated to aphasia assessment and supported self-management rehabilitation will also take place.
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
The project commences in June 2024
</div>
</div>
<br/>
<div id="78" class="study">
<div class="name">
Mood Compass
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Achini Adikari, John Pierce, Nuwan Pallewela, Dana Wong, Ian Kneebone, Brooke Ryan, Nelson Hernandez, Trevor Bremner, Sue Bremner, Kim Barron, Damminda Alahakoon, Miranda Rose
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:j.pierce@latrobe.edu.au" class="email">j.pierce@latrobe.edu.au</a>
</div>
<strong>Country:</strong>
<div class="Location">
Melbourne, Australia
</div>
<strong>Funding Source:</strong>
<div class="Location">
NHMRC Ideas Grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Phase II - Feasibility, acceptability, preliminary efficacy
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
Not sure yet
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Specific software (mobile or computer software; including software designed for telehealth delivery), Artificial Intelligence/Machine learning
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
An aphasia friendly mood tracking app to enable monitoring and self-management of mood
</div>
<br/>
<em>Additional Comments:</em>
<div class="Location">
Currently testing a prototype of Mood Compass at several sites across
</div>
</div>
<br/>
<div id="79" class="study">
<div class="name">
HARP Aphasia Study
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Dr Anna Caute, Professor Vicky Joffe, Professor Reinhold Scherer, Dr Bundy Mackintosh, Mark Allinson, Leila Mirza.
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:anna.caute@essex.ac.uk" class="email">anna.caute@essex.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
Colchester, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
NIHR Research for Patient Benefit grant
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available), Augmentative and Alternative Communication, communication accessibility (e.g. text to speech feature)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
The HARP Aphasia Study started in April 2024. The full title of the project is “Harnessing portable smart-camera technology to support the communication skills of people with aphasia”. The project is based at the North East London NHS Foundation Trust and is led by Dr Anna Caute of the University of Essex. The project is exploring how existing portable smart-camera technology can be used to enhance the expressive language and reading skills of people with aphasia. The project will start with a scoping review of the literature about the use of portable smart-camera technology in communication disabilities and rehabilitation. Then we will conduct a market survey of commercially available apps suitable for use in healthcare. In the second phase of the project, participatory health approaches will be used to design a novel intervention harnessing portable smart-camera technology. We will conduct a series of focus groups and workshops with people with aphasia and Speech and Language Therapists, and will develop a therapy manual for the novel intervention.
</div>
<p><br/></p>
</div>
<br/>
<div id="80" class="study">
<div class="name">
Dara (Inclusive data visualisation for human-centred decision-making)
</div>
<strong>Principle Investigator(s):</strong>
<div class="pi">
Stephanie Wilson, Madeline Cruice, Jo Wood, Nicola Botting, Abi Roper, Niamh Devane, Ulfa Octaviani
</div>
<strong>Email:</strong>
<div class="email">
<a href="mailto:s.m.wilson@citystgeorges.ac.uk" class="email">s.m.wilson@citystgeorges.ac.uk</a>
</div>
<strong>Country:</strong>
<div class="Location">
London, United Kingdom
</div>
<strong>Funding Source:</strong>
<div class="Location">
Engineering and Physical Sciences Research Council (EPSRC)
</div>
<strong>Phase of Research:</strong>
<div class="Location">
Early development work
</div>
<strong>Plan to Commercalise:</strong>
<div class="Location">
No
</div>
<strong>Status:</strong>
<div class="OngoingOrComplete">
Ongoing
</div>
<strong>Category:</strong>
<div class="Location">
Generic software (e.g. dictation software already available)
</div>
<br/>
<b>Brief Description:</b>
<div class="summary">
To investigate how people with language impairments experience data visualisation and to develop inclusive data visualisations.
</div>
<p><br/></p>
</div>
</div>
<div class="sourceCode" id="cb1"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
